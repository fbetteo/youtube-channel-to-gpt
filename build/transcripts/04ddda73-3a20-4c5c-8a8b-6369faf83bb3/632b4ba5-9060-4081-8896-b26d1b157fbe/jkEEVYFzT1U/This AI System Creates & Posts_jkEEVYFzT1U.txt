Video Title: This AI System Creates & Posts Faceless Shorts 24/7 (free n8n template)
Video ID: jkEEVYFzT1U
URL: https://www.youtube.com/watch?v=jkEEVYFzT1U
View Count: 52,000

[00:00] So, this YouTube channel right here got
[00:01] over 680,000 subscribers and almost 221
[00:05] million views. And the craziest part is
[00:07] they've only uploaded 11 YouTube shorts
[00:09] that have been completely generated by
[00:11] AI. And it's not only them. I've seen
[00:13] other YouTube accounts, Instagram, Tik
[00:15] Tok accounts that are doing similar
[00:16] things, which proves there's an audience
[00:18] for this type of content. And this was
[00:19] super interesting to me. So, I decided
[00:21] to build a workflow that can handle 100%
[00:23] of this process as far as creating all
[00:25] of the elements, rendering it all
[00:27] together, and posting on Instagram, Tik
[00:29] Tok, and YouTube. So, here's the
[00:31] inspiration channel, and let's take a
[00:33] look at their most viewed video, which
[00:34] has 93 million
[00:45] views. It's basically two animals being
[00:47] pinned up against each other. And then
[00:49] the next image is basically which animal
[00:51] won. And now if we flip over to my
[00:52] Google sheet content machine that's
[00:54] linked up to this workflow. Let's take a
[00:56] look at an example output.
[00:58] [Music]
[01:09] [Applause]
[01:12] So, that was the gorilla versus wild
[01:14] animals. Let's quickly take a look at
[01:15] polar bear versus big animals.
[01:17] [Music]
[01:29] [Applause]
[01:30] [Music]
[01:36] All right. So, hopefully that just gives
[01:37] you a little bit of a taste of how we
[01:38] were able to replicate the viral shorts
[01:41] using our Naden workflow. So, what we're
[01:43] going to do is a live run. I'm going to
[01:44] walk through the different parts of this
[01:45] workflow and explain what's going on
[01:46] within each step. I'm going to talk
[01:48] about how you can get this template for
[01:49] free and set it up in your own NN
[01:51] environment. And then also at the end,
[01:52] we're going to cover pretty much the
[01:54] total cost of each run. So, if that
[01:56] sounds good to you, let's get started.
[01:57] Okay, so you can already see there's
[01:59] kind of like five main blocks, which is
[02:01] first of all, we're going to be creating
[02:02] the scenes. Then, we're going to be
[02:03] creating those close-up images. So, like
[02:05] the polar bear versus the elephant, two
[02:07] close-ups. Then, we're going to be
[02:09] creating the winner images. From there,
[02:10] we're going to pull all of the pictures
[02:12] back in, render the final video
[02:13] together, and then we're sending it off
[02:14] to Instagram, Tik Tok, and YouTube to be
[02:17] published. Okay, so for this run, as you
[02:19] can see, based on our Google sheet, this
[02:21] is going to be ape versus big cats. and
[02:23] it's going to pull in because we have
[02:24] this marked as to-do. So, I'm going to
[02:26] go back into the workflow. I'm going to
[02:27] hit test workflow and we're basically
[02:28] just going to watch this thing start and
[02:30] we're going to start to break down each
[02:31] step. So, right here, we're accessing
[02:33] the Google sheet. And what we're doing
[02:35] is we're pulling in anything from our
[02:36] viral shorts Google sheet, but the
[02:38] status column has to equal to-do and
[02:40] then we're only going to pull back the
[02:41] first matching row just in case you
[02:43] wanted to like fill this up with weeks
[02:45] worth of content and they were all going
[02:46] to be listed as to-do. We only want this
[02:48] workflow to process one at a time. And
[02:50] of course, the cool thing about the
[02:51] schedule trigger over here is we can
[02:52] just basically have this thing go off
[02:53] twice a day, three times a day, however
[02:55] much you want to do it. And as you can
[02:57] see, what came into this Nad workflow is
[02:59] the ape versus big cats. So after this,
[03:02] we move on to the next step, which is
[03:03] the scene creator agent. And you can see
[03:05] what we give this agent as the user
[03:06] message is two things. The first thing
[03:08] is the main character, where we're
[03:09] basically just passing over the ape. And
[03:12] then the second thing is the type of
[03:13] opponent. So in this case, the type of
[03:14] opponent was big cats. So basically this
[03:17] agent's job is to take the main
[03:18] character and the opponents and as you
[03:20] can see on the right hand side it spits
[03:22] out eight different scenes which are the
[03:23] eight different opponents that the main
[03:25] character is going to be fighting in
[03:27] this YouTube short. So I'm not going to
[03:28] spend too much time on the prompt. Keep
[03:30] in mind you'll be able to download this
[03:31] template for free and play around with
[03:33] it. But basically what we're saying is
[03:34] an AI agent that creates fight scene
[03:36] matchups. You're going to be given a
[03:38] main character and a category of an
[03:39] opponent. And then you need to generate
[03:41] a list of eight different opponents from
[03:42] that category. And real quick before we
[03:44] move on down this workflow, I just
[03:46] wanted to talk about the prompts. The
[03:47] prompts are going to be the secret sauce
[03:48] that creates content, you know, AI
[03:50] generated content that people actually
[03:52] want to watch. So in here, these are
[03:53] prompts that I started with just to show
[03:55] you guys how this works. But if you
[03:56] really want to get in here and customize
[03:57] this template to your needs, I would
[03:59] highly recommend playing with the
[04:00] prompts. And this will also show you how
[04:01] you can customize this workflow to
[04:03] create completely different types of AI
[04:05] generated shorts if you don't like this
[04:07] animal versus another animal type, but
[04:09] you can use this to create whatever it
[04:10] is. And a real quick example of that is
[04:12] if we go to my Instagram, I had a
[04:13] different type of short workflow set up
[04:15] where we were basically, you know,
[04:16] merging different animals together. So
[04:18] there's a parrot with a cat. Here is an
[04:20] eagle with a cat. And as you can see,
[04:22] the actual content of the workflow is
[04:24] very similar, but we just had to play
[04:25] with the prompting a little bit.
[04:26] Anyways, back to the workflow. Now, what
[04:28] we had to do here was a little bit of
[04:30] data transformation. So what we got out
[04:32] of the scene creator was eight different
[04:34] scenes, but what we wanted to do was
[04:36] split those out so we could basically do
[04:38] eight different runs. So, I branched
[04:40] this off to a main character where all
[04:41] I'm doing here is I'm just setting the
[04:43] main character. And then what I did down
[04:45] here was I wanted to set the opponents.
[04:47] So, we could turn that into basically a
[04:48] list of all eight opponents. And then we
[04:50] could basically split that out. And now
[04:52] we have eight different items. And the
[04:54] reason I needed to do this is so when we
[04:56] actually are sending that request to
[04:57] make the AI generated images, we're
[04:59] going to be passing over eight different
[05:01] items. So, eight different opponents and
[05:03] the pictures are going to be generated
[05:04] individually. Cool. So, we have our main
[05:06] character, we have our eight opponents,
[05:08] and then all I'm doing now is I merged
[05:09] it all together. So, we have eight items
[05:11] where we have the main character and the
[05:13] opponent and the main character and the
[05:14] opponent. And so, this just took a
[05:15] little bit of data transformation. And
[05:17] now that we have these eight items,
[05:18] we're able to feed this into the next
[05:20] part of the workflow, which is creating
[05:21] the close-up images. And you can see as
[05:24] we speak, the final video is being
[05:26] rendered right now. Anyways, what we do
[05:28] is we feed those eight items into this
[05:30] image prompt generator where we're going
[05:32] to be giving this agent the main animal
[05:34] and the opponent. And you can tell
[05:36] there's eight separate runs because if I
[05:37] click into the user message, we can see
[05:39] the first item is ape versus lion. The
[05:42] second item is ape versus siberian
[05:43] tiger. The third one is ape versus
[05:45] jaguar. And as you can see, this will
[05:47] just go on for all eight items. But now
[05:49] here's where the magic really happens.
[05:50] And like I said, definitely customize
[05:52] this prompt to your liking. But we have
[05:54] the system prompt, which is basically
[05:55] telling this agent that it needs to
[05:57] generate highquality textto image
[05:58] prompts for photorealistic image
[06:00] generation. It's going to be given a
[06:02] main animal and it's going to be given
[06:03] an opponent and it needs to generate two
[06:05] separate close-up image prompts
[06:07] optimized for cinematic AI generated
[06:09] images. So then I just gave it some more
[06:11] instructions about the output, what they
[06:12] should look like. I said they should be
[06:14] roaring with their mouth wide open. They
[06:15] should look intimidating, all this kind
[06:17] of stuff. And what we get out are eight
[06:19] separate items as you can see. And each
[06:21] item has a main character close-up
[06:23] picture and an opponent close-up
[06:25] picture. So, what you may be thinking is
[06:26] if the main animal is always going to be
[06:28] an ape in this case, can't we just
[06:30] create that ape image once and then use
[06:32] that in all eight different parts? Yes,
[06:34] you can. I chose to do it this way so
[06:36] that all eight ape images just look a
[06:38] little bit different just to keep the
[06:40] audience feeling fresh. Anyways, as you
[06:42] can see, for item one, we have our ape
[06:44] image, we have our lion image. For item
[06:47] two, we have our ape image, we have our
[06:48] tiger image, and then this will go all
[06:50] the way on for our eight items. And the
[06:52] reason we're able to get the items split
[06:53] out like this in two different fields is
[06:55] because if we follow this dotted line,
[06:57] we are using a structured output parser.
[07:00] And if I click into this, it basically
[07:01] says, okay, for each item that you're
[07:03] processing, you need to output the
[07:04] following two fields, which are the main
[07:06] character close-up and the opponent
[07:08] close-up. And as you can see, that's
[07:09] what we get over here. All right. From
[07:11] there, a little bit more data
[07:12] manipulation where we're going to split
[07:14] out those items. So now instead of
[07:15] eight, we have 16 because each of those
[07:17] image prompts we want to process
[07:19] individually. So now we have all 16
[07:21] different animals, a image prompt for
[07:23] them to be a closeup and then we're
[07:25] accessing this PI API endpoint to use a
[07:28] Flux image generator. So here's PI API.
[07:31] It's kind of like an open router for,
[07:33] you know, like different AI models. And
[07:35] what we can do is we can click into
[07:36] workspace and we have image models,
[07:38] video models, audio models, all this
[07:40] kind of stuff. And so what we're doing
[07:41] is we're using Flux's image model
[07:43] through PI API. And if I come in here
[07:45] and I click on task history, you can see
[07:47] that we have all of these different
[07:48] images. It says they're processing, but
[07:50] they're actually done just because we
[07:51] kind of did them in bulk. But you can
[07:53] see that each of these images that we're
[07:55] generating are a little over 1 cent. So,
[07:58] it's not that expensive at all. Anyways,
[08:00] I'm not going to dive too deep into
[08:01] setting up this HTTP request right now,
[08:03] but I actually just released a full
[08:05] guide on APIs for AI agents for
[08:07] beginners. So, if you want to watch
[08:08] that, check it out right up here. But
[08:10] anyways, basically how it goes is we're
[08:11] making a post request to PI API. We have
[08:14] our credential right here as a header
[08:15] off. And then down here in the body that
[08:16] we're sending over, we're saying a
[08:18] couple things. What model do we want to
[08:20] use? We want to use Flux's model. What
[08:22] is the task? We're going to do text
[08:23] image. And then for the actual input,
[08:25] we're just saying how do we want the
[08:26] image to come back to us? First of all,
[08:28] we're dragging over the image prompt. So
[08:29] now you can see this is what we're
[08:31] telling Flux to make. And then this
[08:32] part's pretty important. We wanted this
[08:34] image to be a 1x one, you know, square
[08:36] aspect ratio because at the end we need
[08:39] to have like one image here and one
[08:40] image here and they need to fit
[08:42] together. So, if I show you guys what I
[08:43] mean by that, let's look at our, you
[08:45] know, jaguar versus strong animals. So,
[08:47] here are the close-ups that we just
[08:48] generated. The top half is a bear, the
[08:50] bottom half is a jaguar, and as you can
[08:52] see, it's kind of square ratio. But then
[08:55] the second image that we're going to
[08:56] create later, this one needs to be like
[08:58] that 9x6
[09:00] um portrait style. So, anyways, that's
[09:02] why we're having this one be square. And
[09:04] then you can see this is going to send
[09:05] over 16 different requests and it's
[09:07] going to create 16 different images for
[09:08] us. So what happens is we send over that
[09:10] request and PI API basically responds to
[09:12] us and says okay we're working on that
[09:14] right now and that's why it says status
[09:15] equals pending. So after that we have to
[09:17] just basically wait and I found that
[09:19] this takes anywhere from like a minute
[09:20] to 90 seconds. So we just have this step
[09:22] waiting for 90 seconds just to be safe.
[09:24] And then all we're doing is we're
[09:26] checking back in on those requests and
[09:27] we're saying okay cool. Here's the ID
[09:30] that you gave me for this individual
[09:31] image. Let's see if it's done or not.
[09:33] And yes, one great way to optimize this
[09:35] workflow would be to add a polling
[09:37] feature where we're constantly checking
[09:38] until status equals complete. But just
[09:40] to keep this workflow simple, and I
[09:42] don't want this video to go too long,
[09:43] I'm just going to be checking in after
[09:44] 90 seconds because I know the images
[09:46] will be done. So now you can see we have
[09:48] 16 items, and these are all 16 of our
[09:50] images. And if I was to click into the
[09:52] URL that it returns for um item one, we
[09:55] can see that this is an intimidating
[09:56] looking ape that is roaring at us. If I
[09:59] scroll down to item two and click into
[10:01] this URL, we can see that it is an
[10:03] intimidating line that's roaring at us.
[10:05] And basically, this is just the same for
[10:07] all 16 images. Okay, cool. So, at this
[10:09] point, we have all 16 of our close-up
[10:11] images. And now, I'm aggregating
[10:13] everything back together so that we can
[10:15] make one request to Google Sheets and
[10:17] basically put all of the images in
[10:18] there. And the reason I want to store
[10:20] all of our images in Google Sheets is
[10:22] because we have all the close-ups that
[10:23] are going to go in there and then we're
[10:24] gonna have all the winner images that
[10:25] are going to go in there. And that's 24
[10:27] total images. So it's easier to store
[10:29] them somewhere else for now and then at
[10:31] the end we can pull them all back in
[10:32] rather than having to sort of keep track
[10:33] of them. So as you can see now this ape
[10:36] versus big cats run that finished up. We
[10:38] have all of these different images. And
[10:39] if I click into like you know 5.2 this
[10:41] is going to be um looks like a bobcat
[10:44] that the ape is fighting. And then 5.1
[10:47] this one should be another image of an
[10:48] ape. And the way that we actually tell
[10:50] this node to send data back is we come
[10:53] into the node and what we're doing is
[10:54] we're updating a row within our sheet.
[10:56] Now, this is the most important part of
[10:58] what we're doing here is we're mapping
[10:59] on a certain column and the column we're
[11:01] mapping on is main character. So, this
[11:03] is basically telling Google Sheets which
[11:05] row do you want to update because in our
[11:07] Google Sheets we have all of these
[11:08] different rows and it needs to know
[11:10] which one to send the data back to. And
[11:12] so because we're telling it to match on
[11:14] main character, it's going to look for
[11:15] whichever row in our Google Sheets
[11:17] equals ape because we drag in ape right
[11:20] here. And the way I got that is I scroll
[11:22] all the way back down on this left-hand
[11:23] side to the Google sheet that actually
[11:25] triggered this whole process. And we can
[11:27] see we have main character equals ape.
[11:29] So I just dragged in ape right here. And
[11:31] that way we know every single time that
[11:33] this workflow runs, whatever row it's
[11:35] processing, that's the same row that
[11:37] it's going to update the rest of this
[11:38] workflow. Cool. And then from there, we
[11:40] just have all of these different, you
[11:42] know, fields to actually map, which is,
[11:43] you know, 1.1, 1.2, 2.1, 2.2, and we
[11:47] have eight total stories. So, it goes
[11:48] all the way down to 8.1, 8.2. And this
[11:50] is like annoying the first time you do
[11:52] it cuz you have to drag everything over.
[11:53] But then the variables are already set
[11:55] in stone, and it's always going to
[11:56] process the same way every time. All
[11:58] right. So, now that we have all of our
[11:59] close-up images done, we can move on to
[12:01] the next section of the workflow, which
[12:03] is creating the winner images. So, what
[12:05] we're doing here is once again, we're
[12:06] prompting an AI agent, and we're going
[12:08] to give it two different animals. So up
[12:09] here we have animal one, animal two. Let
[12:11] me make this a little bigger so we can
[12:12] see. Animal one is an ape, animal two is
[12:15] a lion. And that's just for the first
[12:16] scene. And for the second scene, we have
[12:18] an ape versus a Siberian tiger. And for
[12:21] the third scene, we have an ape versus a
[12:22] jaguar. And this is going to go all the
[12:24] way down until we get to our last item.
[12:26] And as you can see on this right hand
[12:27] side, what we get back are eight
[12:28] different image prompts. And each of
[12:30] these image prompts are going to
[12:31] contain, you know, like which of these
[12:33] animals actually won the fight. So, if
[12:35] we look at this first example, and I
[12:36] don't want to spoil anything when we
[12:37] reveal the short later, but we see that
[12:39] an opposing African lion is standing
[12:41] victoriously at top the lifeless body of
[12:43] an ape. So, clearly, the lion won the
[12:45] first battle. So, once again, all of the
[12:48] magic happens in the system prompt. So,
[12:50] I'm not going to read this entire thing.
[12:52] Once again, if you download the
[12:53] template, you'll be able to play around
[12:54] with this, but I definitely encourage
[12:56] you guys to customize the prompts a
[12:57] little bit. But the main piece what
[12:59] we're doing here is we're saying, you
[13:00] know, you're an AI agent that creates
[13:01] text to image prompts for photorealistic
[13:03] image generation. You're going to be
[13:05] given two different animals and you need
[13:06] to write one vivid prompt for a
[13:08] photorealistic image that shows the
[13:10] aftermath of a fight. Decide which
[13:12] animal is the winner and it should be
[13:14] realistic based on the strengths of each
[13:15] animal. Just gave it a few guidelines
[13:17] here. This definitely took me a while to
[13:18] play around with, so I was getting the
[13:19] images the way that I wanted them to.
[13:21] You also have to be careful with certain
[13:23] image generation models like you know
[13:24] can you how violent can the pictures be
[13:27] or you know can they be gory at all. So
[13:28] I had to play around with that for a
[13:29] little bit but basically what I did is I
[13:31] gave it some prompt guidelines. I told
[13:33] it how to output and then I gave it a
[13:34] good example of an image prompt. And
[13:36] once again we got eight different
[13:37] stories output on the right. So we're
[13:40] able to feed those eight different
[13:41] scenes into the exact same process that
[13:43] we did up here. So you could basically
[13:44] just copy and paste these three nodes
[13:46] except for the one thing we have to
[13:48] change is we don't want this picture to
[13:50] be a square aspect ratio. So we came
[13:53] back in here and we changed the width
[13:54] and the height. But after we send over
[13:57] these eight different scenes, it's going
[13:58] to do the exact same thing where it
[14:00] tells us, "Okay, we got your request.
[14:01] We're processing it. Please wait a
[14:03] little bit." So we go ahead and wait 90
[14:04] seconds. We check back in and then we
[14:06] grab all of the completed images. So
[14:08] let's scroll down to a random one down
[14:10] here and we will see who won this fight.
[14:12] Okay, so looks like this one was a tiger
[14:14] that clearly beat up this ape. Anyways,
[14:16] we're doing the exact same thing once
[14:18] again. We're going to aggregate the data
[14:19] and then we're going to push it back
[14:20] into our Google sheet. And you can see
[14:22] our Google sheet now has all 24 elements
[14:25] of the stories have been created and
[14:26] those are all in the.3 section. So here
[14:29] is a bobcat over the ape. If we come
[14:31] over here, we can see this is a the ape
[14:34] that beat up the black panther. Okay,
[14:36] cool. So we have all 24 elements. So you
[14:38] can see the final video is already done,
[14:39] but the next section of the workflow is
[14:41] to render it all together. So we're
[14:43] going to take all 24 images and we're
[14:45] going to stitch them together. So what I
[14:46] had to do was merge all the items
[14:47] together because we have two paths going
[14:49] on. So this merge is going to wait for
[14:50] all the close-up images to finish. It's
[14:52] going to wait for all of the winner
[14:53] images to finish and then it's going to
[14:55] go ahead and move down the process. So
[14:56] the first thing we're going to do is
[14:57] we're going to go grab all 24 of our
[14:59] completed images. And what we do here is
[15:01] similar to the matching thing that we
[15:03] did earlier with Google Sheets. We're
[15:05] saying, you know, which row do we
[15:06] actually want to pull back? So, I put in
[15:08] a quick filter. I said main character
[15:10] has to equal ape. And once again, the
[15:12] way I got to ape is because I went all
[15:13] the way down to the Google sheet that
[15:15] started this process, and I dragged in
[15:17] the main character for this row. Just be
[15:19] careful if you have multiple rows in
[15:21] your content sheet where the main
[15:23] character is an ape. It's going to pull
[15:24] back all of those where main character
[15:26] equals ape. Unless, of course, you come
[15:28] down here and you say, I only want to
[15:29] return the first matching row. But if
[15:31] you only return the first matching row,
[15:32] chances are that one's already been
[15:34] processed. So that's why just be mindful
[15:36] of that. Anyways, you can see we have
[15:38] our ape, we have our big cats, and then
[15:40] we have all of the URLs for all the
[15:43] images that we need. So we're ready to
[15:44] render it all together. So what we're
[15:46] doing here is we're hitting an API
[15:48] called Cremate. And if I click into
[15:49] Creatmate, you can see here are all of
[15:51] my renders and this is our completed
[15:53] video. But what we need to do is we need
[15:54] to go to templates. And so here's a
[15:56] template I made that I'm going to give
[15:57] away to you guys for free. So let me
[15:59] click into this real quick. And
[16:00] basically what this does is we're able
[16:01] to set up this template where we can
[16:03] just basically pass in different images
[16:05] and different text every time and it
[16:07] will be able to stitch it all together.
[16:09] So here's what that looks like. And just
[16:10] imagine we're putting our own images and
[16:12] text in there. But what you can see is
[16:13] it's going to do the two split screen
[16:15] with text and then it's going to show a
[16:16] full image. And it basically does this
[16:18] eight times. And so for you guys to
[16:19] replicate this when you start a new
[16:21] template in Cremate, you'll come up to
[16:23] the top right, hit source editor, and
[16:24] then you'll just be able to copy and
[16:26] paste the source code that I'll give you
[16:28] guys. um right into here and you'll have
[16:30] this exact same template popped up. And
[16:32] one thing you can play around with is
[16:33] the music you want. If you want that to
[16:35] be dynamic, you can definitely have the
[16:36] workflow create music and send that in
[16:38] every time. But what I did is I'm using
[16:40] the same audio file every single time.
[16:42] And I'm just linking that from my Google
[16:44] Drive. But anyways, once you have that
[16:45] template set up, what's cool is that you
[16:47] can basically just click on use template
[16:49] in the top right. You can click on API
[16:51] integration and it will give you this
[16:52] entire curl command where all you have
[16:54] to do then is click on copy. And then
[16:56] when you come back into nen and you open
[16:58] up a fresh HTTP request node, you can
[17:00] basically just import the curl, paste
[17:02] that in there, and then you'll have
[17:03] everything configured already, and
[17:04] you'll just have to drag in some dynamic
[17:06] variables as you can see down here. Or
[17:08] if you do just want to copy and use my
[17:10] exact template, all you'll have to do is
[17:11] when you make your own template, you'll
[17:12] just have to change the template ID
[17:14] right here to the one that's in your
[17:16] Creatmate environment and then you'll
[17:17] have to plug in your own Creatmate API
[17:19] key. So once again, not going to dive
[17:21] too deep into how this works. I linked a
[17:23] you know APIs for AI agents beginner
[17:25] guide earlier in this video. Definitely
[17:27] give that a watch after this video. But
[17:29] at a high level what we're doing is
[17:30] we're making a post request to
[17:31] createate. We are authenticating
[17:33] ourselves right here with a header
[17:34] parameter. So authorization bearer space
[17:38] your creatate API key right there. And
[17:40] then where the magic really happens here
[17:41] is with this body request. And I know
[17:43] this may look very intimidating but it's
[17:45] not too bad at all. So let's talk about
[17:47] what we're doing here. So really when
[17:48] we're sending over a JSON body, it's
[17:50] just basically like different parameters
[17:52] and the values that we want to populate
[17:54] them with. So template ID, this is where
[17:56] you could put in your own create a
[17:57] template ID. Music source, you could
[17:59] throw in your own music source. And then
[18:01] we basically have like our eight
[18:02] different scenes and different elements
[18:04] for each one. So for each scene, we need
[18:05] a top image source, a bottom image
[18:08] source, we need the middle text, which I
[18:09] just manually put in as verses for all
[18:12] of them. And then we need the actual
[18:13] full background image, so the winner.
[18:16] And so all I did is because we have all
[18:18] of the 24 elements right here on the
[18:19] lefth hand side, I just dragged them in
[18:21] to the correct spots where they're
[18:23] supposed to be. And then on the right
[18:24] hand side, you can see that we actually
[18:26] have all of those image links that are
[18:27] going to be sent over to Creatmate. And
[18:29] all it's going to do is put the right
[18:30] images in the right spots because we've
[18:32] already made the template in Creatmate.
[18:34] And this does a very similar thing when
[18:36] we actually send off this request.
[18:38] Creatate basically says, "Okay, cool. We
[18:39] got all your images. We have started the
[18:42] process of rendering this video. Here's
[18:43] the URL that you're going to get when
[18:45] it's done." but it's not done yet. So
[18:47] once again, we're going to wait for 90
[18:48] seconds and then we're going to go ahead
[18:50] and do the same thing where we check
[18:51] back in on the video. And you can see we
[18:53] get it right here as a binary file. So
[18:55] let's take a quick little sneak
[18:57] [Music]
[19:09] [Applause]
[19:13] peek. Okay. Anyways, now like the
[19:15] hardest part is done. We have the final
[19:17] video rendered and basically what we
[19:19] want to do is send that back into Google
[19:21] Sheets and then we want to upload it to
[19:23] the different socials. So once again,
[19:25] we're pulling up a Google Sheets and
[19:26] we're going to do an update row. We're
[19:28] going to do the exact same thing as
[19:29] earlier where we're going to match on
[19:30] the main character, which in this case
[19:32] is the ape. And then all we're going to
[19:33] do is two things. We're going to change
[19:35] that status to created so then it
[19:37] doesn't get pulled in again. And then
[19:38] we're going to send over that final
[19:39] video URL right here. And that's the one
[19:41] that I was clicking on earlier that
[19:43] pulls up the actual finished video. So
[19:45] then what we want to do is we want to
[19:47] post them to our Instagram, Tik Tok, and
[19:49] YouTube. And you could even do different
[19:51] ones as well if you want. And we're
[19:53] doing this through a service called
[19:54] Blot. And Blotato actually has nine
[19:57] different things you can connect to. So
[19:58] Twitter, LinkedIn, Facebook, Tik Tok,
[20:00] Instagram threads, Pinterest, Blue Sky,
[20:01] and YouTube. In this video, we are only
[20:03] doing these three, but you can connect
[20:05] to all nine. So if you guys want to see
[20:06] a video on how that works, let me know.
[20:08] But anyways, there's two main elements
[20:10] here. The first one is we have to upload
[20:11] our video to Blotato and then we can
[20:14] take that Blotato URL that it gives us
[20:16] for that video and then we can push it
[20:18] to wherever we want. So the first step
[20:19] is to upload to Blot. And by the way,
[20:22] there'll be links for all of the
[20:23] services down in the description as well
[20:24] as if you download this template,
[20:26] there'll be a little setup guide right
[20:27] here with all the links. But anyways, in
[20:29] this HTTP request to Blot, what we're
[20:31] doing is we're making a post request to
[20:33] Blot's endpoint where we're going to
[20:35] upload media. We have to put in our API
[20:37] key. So I saved that right here as a
[20:38] header off and then we're sending over a
[20:40] body which is literally just one thing
[20:42] and that's the URL of our final video.
[20:44] So all I did is I put URL as the name
[20:46] and then I dragged in the final video
[20:48] right from here and now is getting that
[20:50] final video and it basically just sends
[20:52] us back another URL and you can see if I
[20:54] open this up in the browser it'll be the
[20:56] exact same video that we already
[20:59] created. The only difference is now it
[21:01] is stored within Blot's database so that
[21:03] it can actually post it for us. So we
[21:05] have it split out into three different
[21:06] paths now. The first one is Instagram.
[21:08] These are all basically the same thing,
[21:09] but we'll still look through each of
[21:10] them. So what we're doing here is we're
[21:12] making a post request to Lotato once
[21:14] again, but we just tell it later that
[21:16] we're going to do Instagram. So anyways,
[21:18] here's the endpoint we're accessing.
[21:19] We're putting in our API key once again.
[21:21] And then in the body request, here's
[21:23] where we can actually change things a
[21:24] little bit. We tell it right here,
[21:26] target type Instagram. We give it the
[21:28] actual text of like the caption. So in
[21:30] this case, all I did is I put ape versus
[21:32] big cats. And I did that just by pulling
[21:34] in from that Google sheet the main
[21:36] character and then I typed in versus and
[21:37] then I dragged in the
[21:39] opponents. Once again, we have the
[21:41] platform equals Instagram. We have the
[21:43] actual URL that Blot just gave us. So I
[21:45] dragged in this one from right here. Put
[21:47] it right there. And then all you need to
[21:48] do is you need to put in your Instagram
[21:50] account ID. So when you're in Blotato
[21:52] and you connect your accounts, as you
[21:53] can see, I've connected these three
[21:54] right here. What happens is you can
[21:56] click a copy account ID. So, all I did
[21:59] is I clicked copy my Instagram account
[22:00] ID, came back and ended in, and then I
[22:03] pasted that right there. And then when
[22:04] you post that, it'll just basically give
[22:06] you a ID of your post. And that's how
[22:08] you can make sure it actually went
[22:09] through. So, if I come into Bot, I can
[22:11] see right here, Ape versus Big Cats, and
[22:13] this one was posted on Instagram. And I
[22:14] can actually click into this URL, and it
[22:16] will show us the post. And then it's
[22:18] very similar for Tik Tok except for
[22:20] there's a few different parameters to
[22:21] send over. So, same endpoint, same
[22:22] method, same credential. And then here,
[22:24] we just have a few other things to fill
[22:26] out. So I filled that out according to
[22:28] Blotato's documentation. Once again, all
[22:31] of this will be in the template if you
[22:32] choose to download it. And then the only
[22:34] difference is the platform this time is
[22:35] Tik Tok and then we have to do a
[22:36] different account ID. So you come in
[22:38] here, click on copy account ID and then
[22:40] you'll paste in your Tik Tok account ID.
[22:42] And then you come here and you can click
[22:43] on the Tik Tok link for that video to
[22:45] make sure that it actually got posted.
[22:47] And as you can see right here, it did.
[22:49] And then I just noticed it didn't
[22:50] actually post the YouTube one. I'm
[22:51] assuming it did because we can see that
[22:53] the node is green. And I'm assuming it
[22:56] gave us an ID, so maybe it just didn't
[22:57] show up in Blotato yet. But we'll
[22:58] definitely go check the actual YouTube
[23:00] account in a sec. But anyways, here's
[23:02] another way to post through YouTube. You
[23:03] could do it natively. In a previous
[23:05] Facebook shorts video, I was posting
[23:07] through YouTube natively, as you can see
[23:09] right here. But I figured might as well
[23:10] show how to do it with potato. So
[23:12] anyways, pretty much the exact same
[23:14] thing. Same endpoint, same method, same
[23:16] credential. And then we need to come in
[23:18] here and we just have a few things to
[23:19] configure, which is the platform and the
[23:21] target type is YouTube. We have our
[23:23] title. We have a little description and
[23:25] then we have our account ID once again.
[23:28] So, same thing. You'll go to Plotato.
[23:29] You'll click on copy account ID and then
[23:32] you'll basically just paste that in
[23:33] right there. So, yeah, not exactly sure
[23:34] what happened with potato here. You can
[23:36] see that it posted to YouTube earlier
[23:37] for me, but it did show up here as an
[23:39] unlisted video. So, it's working. And
[23:42] you can see I've experimented with some
[23:43] other types, you know, cats and birds
[23:45] had babies, farm animals versus Donald
[23:46] Trump, Elon Musk, other stuff like that.
[23:49] What I really want you guys to take away
[23:50] from this video is, you know, you have a
[23:52] template, but it's really just supposed
[23:53] to be a nice skeleton to show you how
[23:54] pieces move through, show you how you
[23:56] may need to do some things like store
[23:58] data, third party, pull it all back at
[23:59] the end, and you can really get creative
[24:01] here with your different image prompts.
[24:03] You can even turn those images into
[24:04] videos. You can render everything
[24:05] together in a different style. You can
[24:07] play with different sound effects and
[24:08] stuff like that. What I think is really
[24:09] cool is to be in that mindset where you
[24:11] see something and you think to yourself,
[24:12] I bet I could automate that. I don't
[24:14] know exactly how that's going to work,
[24:15] but I'm going to play around with, you
[24:16] know, different APIs and I'm going to
[24:18] play around with different tools and
[24:19] different data manipulation techniques
[24:21] and I know I can automate that if I, you
[24:23] know, sit down and end it in and I give
[24:25] it my best shot. But anyways, now that
[24:27] we have this on all three of our
[24:28] socials, let's just watch the final
[24:29] video real quick to see how it turned
[24:32] [Music]
[24:36] out. Heat. Heat.
[24:39] [Music]
[24:44] [Applause]
[24:45] [Music]
[25:03] So, I'm sure there's a few things you
[25:04] guys may have noticed as far as maybe
[25:06] not perfect consistency between the
[25:08] close-up and the actual fighting image.
[25:10] And that's obviously because the image
[25:12] generator doesn't have the first
[25:13] close-up as context. So, there's a lot
[25:16] of ways to optimize these types of flows
[25:18] and do some really cool things as far as
[25:19] like creating completely automated AI
[25:21] generated content. What you could do is
[25:23] have some sort of story where you create
[25:24] an image and then you feed that image
[25:26] into an AI image generator and you say,
[25:28] "Hey, look at this image and look at
[25:29] this next scene and then create the next
[25:31] scene based on it to keep consistency."
[25:33] And so, that would be a little bit more
[25:34] of complex flow, but it would definitely
[25:36] provide some really high quality
[25:37] outputs. If you guys are interested in
[25:39] seeing that sort of like storytime type
[25:41] of content automated, let me know. I'd
[25:43] love to make a video on that and show
[25:44] you guys how that works. Anyways, what I
[25:46] think is cool about this is it's a very,
[25:47] very lean system. There are definitely
[25:49] ways we could optimize this. Like, we
[25:51] could have the all the images running in
[25:53] parallel rather than waiting for the
[25:55] close-ups to finish to begin the
[25:56] winners. We could also do what I just
[25:58] talked about with having more
[25:59] consistency across the stories. We could
[26:00] have custom sound effects come in based
[26:02] on the animals and based on what they
[26:04] may sound like. There's so many ways to
[26:05] optimize this, but what I wanted to do
[26:07] is give you guys a cool skeleton to play
[26:08] around with. hit run in your own
[26:10] environment, watch the images be made,
[26:12] watch the data flow through the process,
[26:13] and really start to think how you
[26:15] yourself could improve on this workflow.
[26:16] So, anyways, let's talk about cost real
[26:18] quick before we wrap up because I'm sure
[26:20] that's what you guys want to know if you
[26:22] want to start to run, you know, like a
[26:23] faceless channel on autopilot. So, I
[26:25] threw together a little doc that's going
[26:26] to break down the cost per video for the
[26:28] system. And the first element here is
[26:30] the image prompt generation. So in the
[26:33] workflow what we have are you know we're
[26:35] using open router to connect to 4.1 mini
[26:37] and also 4.1. We're using 4.1 mini for
[26:40] the scene creation which is just which
[26:42] eight animals do we want and then also
[26:44] the close-up images. And then I decided
[26:46] to use 4.1 which is a little more
[26:47] powerful for the winning image prompts.
[26:50] Now this is literally going to be like 1
[26:52] cent per run probably even less. And if
[26:54] you don't believe me you can come into
[26:56] open router and you can see this is the
[26:57] run we just did. So all of these that
[26:59] that you know have like 1215 um every
[27:02] single time we're using it it's
[27:03] basically like
[27:05] 0.00002 or
[27:07] 0.00001. So when I added all that up it
[27:09] was like 1 cent. And then what we move
[27:11] on to is kind of the bulk of the cost
[27:13] which is generating the images but we're
[27:15] using Flux through PI API which is super
[27:17] cheap. It's 1.5 cents per image. And if
[27:21] we're doing 24 images it's 36. So not
[27:24] too bad. It would definitely get more
[27:25] expenses if we wanted to turn all of
[27:26] those images into videos or even just
[27:28] the eight winning videos. But if you
[27:30] remember going back to that channel that
[27:32] was going viral with this stuff, these
[27:34] are just images. They have a little bit
[27:36] of a zoom effect which we kind of
[27:37] replicated with that template. This is a
[27:39] little bit different. But these were
[27:40] just images and that's what I was like,
[27:42] okay, this could be cool to automate.
[27:43] And then the third part of this is the
[27:45] video rendering using creatimate. And so
[27:47] what I'm on is the essential plan. If I
[27:49] come down here, we can see, you know,
[27:51] change plan. The essential is 41 bucks a
[27:53] month. If you're build annually, you get
[27:54] 2,000 credits. And if we click on my API
[27:57] log, sort of like task history, we can
[27:59] see that each run is using 17 credits.
[28:01] 17.69. 17.69 cuz they're all the same
[28:04] amount of seconds. So if we're getting
[28:06] 2,000 credits and each one is 17, we can
[28:08] do about 117 renders, which comes out to
[28:10] about 35 cents a render. And then
[28:12] finally, with the publishing and
[28:13] scheduling, which is kind of an optional
[28:15] cost because you'll get the final video
[28:16] either way. The growth plan for potato
[28:18] is 29 bucks a month and that gives you
[28:20] unlimited scheduling and publishing.
[28:22] Plot also has some AI features which
[28:24] that's kind of what you're paying for
[28:25] with like the credits, but you can still
[28:26] do the automated posting and scheduling
[28:28] on nine different platforms with potato.
[28:30] So, I didn't factor that into the per
[28:32] video cost. But, as you can see down
[28:33] here, it's pretty much under a dollar
[28:35] per run, which I think is pretty solid.
[28:37] But anyways, now that we talked about
[28:38] cost, how do you get this system and
[28:41] plug it into your own NAN environment?
[28:43] Well, there's two things you got to do.
[28:45] Kind of more than that, but two main
[28:46] things. The first one is you have to
[28:48] download this workflow and import it
[28:49] into nitn. So what you'll do is you'll
[28:51] join my free school community. The link
[28:52] for that down in the description. Once
[28:54] you get in here, you'll click on YouTube
[28:56] resources and you can see I have all the
[28:57] videos that I've made on YouTube right
[28:59] here. Or you can search for the title of
[29:01] this video right up here in the search
[29:02] bar and the post will pop up. And when
[29:05] you click on the post, all you have to
[29:06] do is you'll have a JSON file right here
[29:08] which you'll click on download. And then
[29:09] when you come back into Nit, you'll open
[29:11] up a new workflow and you can in the top
[29:13] right import from file. You'll import
[29:15] that JSON file and it will basically
[29:17] just pop up this workflow with a little
[29:19] setup guide right over here. And then
[29:20] another really important part is going
[29:22] to be this exact same Google sheet that
[29:23] I'm using here. So there'll also be a
[29:25] link to the template in the school
[29:27] community wherever I make this post. And
[29:29] you need this exact same template with
[29:31] the exact same column names. Otherwise,
[29:33] the mappings that I set up in NAN are
[29:36] not going to work. So you can grab that
[29:38] template for free as well and make a
[29:40] copy of it and then you'll be able to
[29:41] pull it into your own NAN workflow. And
[29:43] then from there, the other things you'll
[29:44] have to do will be listed on the setup
[29:46] guide, but it's basically just like, you
[29:47] know, connect your open router API key,
[29:49] connect your PI API API key, connect all
[29:51] your different API keys, and then you'll
[29:53] be good to go. Okay, so that's going to
[29:54] do it for this video. If you enjoyed
[29:56] this walkthrough and this is the kind of
[29:57] stuff you're interested in, then
[29:58] definitely check out my paid community.
[29:59] The link for that's down in the
[30:00] description. We just hit 1.5K members,
[30:02] growing super super quick, and everyone
[30:05] in here is pretty much automating things
[30:07] with Naden. Not only is it a great
[30:09] community to ask questions, collaborate
[30:11] with people, but we also just launched
[30:12] two new courses in here. Agent Zero,
[30:14] which is kind of the foundations of
[30:16] building automations, and then 10 hours
[30:17] to 10 seconds, which is like
[30:19] identifying, designing, and actually
[30:21] building automations. So, anyways, I'd
[30:23] love to see you guys in this community,
[30:24] but that is going to do it for the
[30:26] video. Really appreciate you guys making
[30:27] it to the end of this one. If you
[30:28] enjoyed, if you learned something new,
[30:30] definitely give it a like. It helps me
[30:31] out a ton. And as always, I appreciate
[30:33] you guys making it to the end of the
[30:34] video. Thanks everyone. See you in the
[30:36] next one.