Video Title: Step by Step: RAG AI Agents Got Even Better
Video ID: wEXrbtqNIqI
URL: https://www.youtube.com/watch?v=wEXrbtqNIqI
View Count: 63,336

[00:00] in this video I'll be walking through
[00:01] step bystep how to build out this rag AI
[00:03] agent system that uses postgress and
[00:05] super base what we're building today is
[00:07] a little bit more improved version of
[00:08] other rag Builds on this channel and
[00:10] we'll dive into why you want to set up
[00:11] your foundation like this in order to
[00:13] have a rag system that's a little bit
[00:14] more production ready and make sure you
[00:16] guys stick around to the end of this one
[00:17] because I'm going to go over some tricks
[00:19] in setting up the workflow so that
[00:20] anytime a new file is created it's
[00:22] automatically going to go into your
[00:23] super base as well as if you update any
[00:25] of those old records it's going to
[00:26] replace them in your super base so that
[00:28] you know you can always trust the data
[00:29] that you're talking to
[00:30] so here's the rag agent that we'll be
[00:31] working with today if you're unfamiliar
[00:33] with the term rag or you've just sort of
[00:34] heard about it it stands for retrieval
[00:36] augmented generation and it's as simple
[00:38] as the agent here's our question it has
[00:41] to go out somewhere to retrieve that
[00:42] information then it takes that
[00:44] information back generates an answer and
[00:46] then gives us that nice clean answer so
[00:48] retrieval and generation are kind of the
[00:49] two main parts of retrieval augmented
[00:51] generation you can sort of just think
[00:53] about it as if someone asked you a
[00:55] question and you're not sure so you go
[00:56] and Google it and then once you
[00:58] understand the information you give them
[00:59] back back a response but anyways here is
[01:01] the system we'll be building today
[01:03] here's a look at the old one that uses
[01:04] window buffer memory as well as pine
[01:06] cone so I'm going to break down you know
[01:07] why I think postgress is better than
[01:09] window buffer memory and we'll talk
[01:10] about the differences between super base
[01:12] and pine cone but before we do that
[01:13] let's just hop into a quick
[01:14] demonstration so I've already went ahead
[01:16] and uploaded this document to our Vector
[01:18] store which is just information about a
[01:20] fake project called project Mountain so
[01:21] we're going to hop in here and we'll ask
[01:23] the agent what are the action items for
[01:25] project mountain and who are the parties
[01:26] involved so we'll send this off we'll
[01:28] watch it take place and as it's going on
[01:30] I just wanted to mention real quick both
[01:31] of these workflows that we'll be going
[01:32] over today will be available for
[01:34] download in my free school Community
[01:35] Link for that will be in the description
[01:37] you'll just download that Json you'll
[01:38] come up here and then you'll import from
[01:40] file and you'll have the stuff up and
[01:41] running ready to go and if you're
[01:43] looking to take a automations a little
[01:44] further and you want some Hands-On
[01:45] learning experience and help then feel
[01:48] free to join my paid Community Link for
[01:49] that will also be down in the
[01:50] description and then if you're sort of a
[01:52] small business or you're looking to have
[01:54] me Implement these systems for you have
[01:56] me build them out for you then please
[01:57] book a link in my um website which will
[02:00] also be linked down in the description
[02:01] but let's take a look and see what this
[02:03] um agent was able to respond to us with
[02:06] so it said here are the action items for
[02:07] project mountain and the parties
[02:08] involved um as follows so we have
[02:11] collect feedback samples we have Sarah
[02:12] doing that we have metrics which will be
[02:14] John it's giving us due dates as well
[02:16] and then it's basically just summarizing
[02:17] everything that's going to be going on
[02:18] within this project and sort of the
[02:20] timeline going on with it um so we can
[02:23] go into subbase real quick and obviously
[02:25] here's the quick vectorization of the
[02:28] project mountain and then we also have
[02:29] our post Cress memory in here where we
[02:31] can see the human asked what are the
[02:33] action items for the project Mountain
[02:34] who part is involved and then we can see
[02:35] the AI responded with this information
[02:38] so that's sort of how this is going to
[02:39] work um real quick before we get into
[02:41] the actual step by step we have this
[02:43] interface obviously where we're talking
[02:44] to the agent and then we have this
[02:46] workflow that's going on in the back end
[02:48] which is um automatically putting stuff
[02:50] into super base based on um a Google
[02:53] Google drive folder and then also
[02:55] anytime a file in there is updated it's
[02:57] also um updating that record in super
[03:00] base as well as deleting the old record
[03:02] so that we're only interacting with
[03:04] relevant upto-date information all right
[03:06] we're about to get into the step by step
[03:08] so if you want to skip this part feel
[03:09] free but I'm just going to break down
[03:10] the difference between postgress window
[03:11] buffer memory pine cone super base at a
[03:14] really high level so first of all why is
[03:16] postgress going to be better than window
[03:17] but for memory the first thing is about
[03:19] data safety and persistence so postgress
[03:21] SQL is sort of how we're putting the you
[03:23] know the chat memory like we just saw
[03:25] and it's going to keep your data safe
[03:26] even if nadn or your system restarts
[03:28] because when you use the window for
[03:29] memory it's sort of temporary and then
[03:31] it's going to wipe everything when
[03:32] closed so even the window buffer memory
[03:34] is super super easy to set up because if
[03:36] you can see in here if we unconnect this
[03:38] and we go to window buffer memory that's
[03:41] all it is it's no credentials all you're
[03:42] going to do is set your context window
[03:43] length but you know in postgress you
[03:45] have to connect your credentials and
[03:46] make sure everything's set up but it's
[03:47] still not too difficult but that's one
[03:49] of the advantages of the window buffer
[03:50] memory second thing about postgress is
[03:52] that it's scalable for Big Data so it's
[03:54] going to handle large data sets more
[03:55] efficiently and you're going to be able
[03:56] to search through them using powerful
[03:57] tools like indexing um which is
[03:59] obviously very important for rag
[04:01] workflows especially once you get more
[04:02] documents and more things um to chat
[04:04] with and then finally easy integration
[04:06] and long-term use post gr postgress SQL
[04:08] is going to work seamlessly with n 's
[04:10] databases it's obviously got nodes that
[04:12] are going to support multiple users and
[04:14] it's just going to be really reliable
[04:15] and you know future proof as you sort of
[04:17] add on to these workflows next we're
[04:19] talking about real quick super base
[04:20] versus pine cone obviously I've been
[04:21] using pine cone a lot and it's great so
[04:23] we're just kind of breaking down the
[04:24] difference so first of all the purpose
[04:26] super base is sort of a backend platform
[04:28] with um it also has built- in relational
[04:30] databases whereas pine cone is sort of
[04:32] more of just fully managed on Vector
[04:34] databases um which is really good at you
[04:36] know their Vector search and similarity
[04:38] queries for scalability subase is going
[04:40] to be better for small to medium scale
[04:42] Vector storage because they also have
[04:43] those relational queries and relational
[04:45] database um Integrations as well whereas
[04:47] pine cone is going to be more large
[04:49] scale Vector searches billions and
[04:50] billions of vectors you know different
[04:52] indexes different um name spaces to
[04:53] search through that sort of thing
[04:56] hosting subase can be self-hosted or
[04:58] used as a manag service while pine cone
[05:00] is going to be sort of a sass so there's
[05:01] no self-hosting option there and then
[05:03] for the use case to base ideal for um
[05:05] you know relational data metadata Vector
[05:07] search while pine cone is more for the
[05:09] like I said large scale Vector search
[05:11] with sort of minimal operational
[05:13] complexity so now that we understand
[05:15] that um I hope that makes sense as far
[05:16] as you know future use cases when you're
[05:18] trying to figure out what to use here
[05:19] and there what to plug in but now let's
[05:21] get into that step-by-step build all
[05:23] right just to open up a new workflow the
[05:24] first thing that we're building out here
[05:25] is the rag agent so we're going to come
[05:27] in here obviously and grab an AI agent
[05:30] we will leave this one as a tools agent
[05:32] and as far as system prompt um for now
[05:34] we will just basically say your helpful
[05:36] assistant you will use the vector
[05:41] database
[05:43] to retrieve relevant
[05:47] information and respond to the
[05:52] users query um and for now that will be
[05:54] simple enough cuz the only tool we're
[05:56] really plugging in is um you know the
[05:58] vector store so we we'll leave it as
[05:59] this for now um we're going to connect
[06:02] our chat model open AI um I'm going to
[06:05] use 40 mini for this case it's um you
[06:07] know it's it's powerful while being a
[06:09] lot more cost effective than 40 um and
[06:12] for this use case it will be fine you
[06:13] know as we're sort of just demoing but
[06:15] you know as you get more data you need
[06:17] to search through and more complex
[06:18] information you could probably go to for
[06:20] or um you know Claud so from here we
[06:23] have memory obviously we talked about
[06:25] the difference between um window buffer
[06:27] memory and then postgress so we're going
[06:28] to be doing postgress in this case
[06:30] and you need to obviously connect to
[06:31] your account so what you're going to do
[06:33] here is create a new credential you'll
[06:34] come in here and you'll see that you
[06:35] have this information to configure which
[06:37] is definitely a little more daunting
[06:38] than um setting up window buffer memory
[06:41] but it's not too bad so let's hop into
[06:42] super base so that we can get this
[06:44] information we need so if you haven't
[06:45] created a superbase account go ahead and
[06:47] do that real quick so once you're in
[06:49] superbase it's going to prompt you to
[06:50] create a project so you're going to come
[06:51] in here you just need to name your
[06:52] project you need to give it a
[06:54] password um make it
[06:58] stronger okay need to be even stronger
[07:00] than that okay and then you have to
[07:01] remember this password obviously so you
[07:03] can copy it want to put that somewhere
[07:04] safe because this is going to help you
[07:05] set up stuff in the future um I'll just
[07:08] going to leave this as default and then
[07:09] we'll hit create new project okay it
[07:11] will probably take a few minutes to set
[07:12] up your project as you can see up here
[07:13] it's setting it up still but you can see
[07:15] some things like um we have our API keys
[07:17] so obviously we'll use this later when
[07:18] we're setting up the super super base
[07:20] Vector store tool within nadn but we're
[07:23] waiting for it to set up some
[07:24] information as you can see it just went
[07:25] through okay so once you got that
[07:26] project set up you're going to go down
[07:28] to the left hand side click on Project
[07:29] settings you will go to database right
[07:31] here and then you'll have this screen
[07:32] pulled up and this is the information we
[07:34] need to set up the postgress so we can
[07:35] see host we're going to grab that real
[07:37] quick Copy it over paste it into host we
[07:40] will go to um our Port grab that and
[07:44] then this is going to be down here at
[07:45] the bottom we'll plug in the port right
[07:47] here um what else do we need the
[07:49] database should always be postgress so
[07:50] we need to grab our user which will be
[07:52] right here we will paste that into there
[07:55] and then the password as you can see
[07:57] that's just um the password you typed in
[07:58] earlier so let me do that real quick and
[08:00] once you put in your password hit save
[08:02] and then you'll see connection tested
[08:03] successfully let me just call this one
[08:05] real
[08:06] quick demo so we have this set up here
[08:09] and now once that's configured we don't
[08:11] really need to change anything else here
[08:12] the table name is just going to be the
[08:14] table that goes into um our super base
[08:16] that we can look at our chat history so
[08:17] we can leave that as is and then context
[08:19] window length just how many interactions
[08:20] the model is going to be looking at for
[08:22] context so five should be fine if you
[08:23] want to bump it up to 10 or 20 you can
[08:26] do so let's just go with 10 for now and
[08:28] that's basically it so we have our
[08:29] memory set up every time we talk to the
[08:31] agent and the agent talks to us the
[08:32] memory will be put into our super base
[08:34] um in a table called NN chat history I
[08:37] think it was so now let's set up the
[08:38] super base so obviously we're going to
[08:40] be adding a tool and we're going to type
[08:41] in Vector store we can see Vector store
[08:43] tool right here we need to name this so
[08:45] we will just call this um what are we
[08:47] pulling in Project data so I'll just
[08:48] call this projector
[08:51] data we will also do the same up here
[08:54] and then we need to obviously describe
[08:56] what this tool is so it's going to
[08:58] retrieve information
[09:00] about the projects and so that should be
[09:02] good for now um we've got project data
[09:04] now we need to obviously connect to
[09:06] model we're going to go with for minu
[09:08] once again and then we're going to go
[09:09] into Vector store and we're grabbing
[09:11] superbase and we need to set up these
[09:12] credentials as well so we'll click
[09:13] create new credential we need to get a
[09:15] host and a service R secret so back in
[09:17] um subbase you might see host here this
[09:19] is not what you're going to grab you
[09:21] want to go to the leth hand side go to
[09:22] Project settings you're going to click
[09:24] on API and then up here this URL that's
[09:27] going to be the host so you copy this
[09:29] you'll paste that right in there and
[09:31] then in here you need to click on for
[09:33] your service Ro secret you'll click
[09:34] reveal you'll copy it paste that into um
[09:38] you know obviously this section right
[09:39] here so let me do that real quick okay
[09:40] we got the huge service R secret po
[09:42] pasted into there we'll hit save should
[09:44] go green we're good to go and let me
[09:46] also just rename this one demo we got
[09:49] the credential set up and now obviously
[09:50] the operation is in this case we're
[09:52] retrieving documents but now we need to
[09:54] set up the table so if you come in here
[09:55] you will have no results because this
[09:57] current project that you just connected
[09:58] to you haven't set up the table yet yet
[09:59] so what we're going to do is click on
[10:01] docs right here it's going to pull up
[10:02] the NN docs and then we have a super
[10:04] quick start for setting up your vector
[10:06] store so you're going to click into this
[10:08] and we have this chunk of code right
[10:09] here all we're going to do here is hit
[10:12] copy we'll go back into super base and
[10:15] we're going to go to our SQL editor over
[10:17] here on the left side we'll paste this
[10:19] in that's all you have to do is paste it
[10:20] in you could go in here and change stuff
[10:22] if you want the table to be named
[10:23] something else if you want to change
[10:24] some of these matching criteria but I
[10:27] don't touch anything you're just going
[10:28] to hit run and you should see success no
[10:30] rows returned so now once we go into the
[10:33] table editor we will refresh and we
[10:36] should see right here a table called
[10:38] documents so this is our documents um
[10:40] Vector store that we'll be putting
[10:41] information into we'll get records
[10:43] filled into here that we can look at
[10:45] once we actually put documents into it
[10:47] so that's there and then also another
[10:49] one right here will pop up that's the
[10:50] one that will be ended in chat history
[10:51] and we can see what we've been been
[10:53] saying to the agent but anyways back in
[10:55] NN now we need to choose the table we
[10:57] should see not yet so let refresh and
[10:59] ITN real quick okay now that we
[11:01] refreshed it we should be able to come
[11:02] in here see our table which will be
[11:04] documents we're going to grab that and
[11:06] then we need to add an option of query
[11:07] name and leave it as match documents so
[11:10] we're good to go here um all we need to
[11:12] do now is set up the embedding so we're
[11:14] going to set up um text embedding three
[11:16] small which is kind of the default right
[11:17] now so we've got that set up we'll hit
[11:20] save um if you've watched some other
[11:22] videos with pine cone when you're
[11:24] actually setting up your index you will
[11:26] see an option to choose the embedding
[11:28] that you want in your vector store so
[11:29] that's when you'd set up embedding three
[11:30] small and then you'd want to choose that
[11:31] one in here as well but in sub base you
[11:33] don't actually go through that process
[11:35] of manually setting that up but we're
[11:36] going to do embedding three small so
[11:38] hopefully um not any confusion there but
[11:41] this is going to be it as far as the
[11:42] agent um you know there's no information
[11:44] in there so if we said like what are our
[11:47] projects looking like it's obviously not
[11:49] going to return anything because we
[11:50] haven't built out that workflow that is
[11:52] going to um so it actually went and
[11:55] searched but it's not going to return
[11:56] any actual information it seems I'm
[11:58] unable to retrieve information about our
[11:59] current projects so now we need to go
[12:01] through the process of you know actually
[12:03] putting information into that Vector
[12:04] store okay so in this workflow we're
[12:06] going to start this one off with a
[12:07] Google Drive trigger um we'll come into
[12:09] Google Drive the trigger is going to be
[12:10] on changes involving a specific folder
[12:11] so we'll grab that you need to set up
[12:13] your credentials um I've walked through
[12:15] this in multiple videos early on um also
[12:17] in my NN master class but if you don't
[12:19] understand you're basically just going
[12:20] to go in here you can click open docs
[12:22] and it will walk you through exactly how
[12:24] to set up your Cloud account um you know
[12:26] set up your your credentials your o
[12:28] consent screen that kind of stuff and
[12:30] it's it's super simple so you go into
[12:32] there do that the first thing we see is
[12:34] that once this trigger is active so the
[12:36] workflow is not active yet so it won't
[12:37] be doing this but when it when it is
[12:39] active every minute it will be checking
[12:41] in this folder so it's going to be
[12:42] looking for changes involving a specific
[12:44] folder which we will choose projects
[12:46] oops projects as you can see in here we
[12:49] have my folders called projects with
[12:51] project mountain in it that we used in
[12:53] the demo and then we're looking for a
[12:55] file created so anytime a file is
[12:56] created this will go off and then the
[12:58] logic will take place to upload it into
[13:00] Tu base and as you can see right here
[13:02] we've got project mountain right there
[13:04] so this is the correct folder and we
[13:06] know it's working and so we can move on
[13:08] to the next step which is going to be we
[13:10] want to set the ID from from the um file
[13:15] that's being pulled in we want to make
[13:16] sure that we have the the ID of the file
[13:19] that's that's coming through so that we
[13:21] can download it and then we can also put
[13:22] the ID into the metadata of subbase so
[13:25] that later when we want to update a file
[13:27] we can grab that metadata in order to to
[13:29] delete those records and then upload the
[13:30] new one so in here we're going to be
[13:33] doing a string we will just call this
[13:35] file ID and then we're going to drag in
[13:38] the value so you have to look through
[13:41] you know all the information that's
[13:42] coming back and it may may look
[13:43] intimidating so we're just going to
[13:44] close out of this stuff what we'll be
[13:46] looking for is near the bottom um we're
[13:49] looking for the spaces ID so you see an
[13:51] ID right here permission ID you're not
[13:54] going to grab that one that will not
[13:55] actually link to the um correct document
[13:58] and if you want to make sure you're
[13:59] doing it right we're going to grab
[14:00] space's ID but if you want to make sure
[14:02] you're doing it right you can go to the
[14:03] Google Doc um that you're actually
[14:06] pulling into that um folder and in the
[14:09] URL you will see this ID so that's how
[14:11] you know that it's referencing the
[14:12] correct document and also later if you
[14:14] did the wrong one you'll be able to tell
[14:16] because when we download it's not going
[14:17] to work but if we test the step we
[14:19] should see the file ID is coming back so
[14:20] we're good to go here so now we actually
[14:22] want to download this file so we're
[14:23] going to do once again at Google Drive
[14:27] um and then we're going to go down
[14:28] Within file actions to download a file
[14:30] so grab that um so obviously we're
[14:33] downloading a file here and this is
[14:34] where you know typically you could
[14:36] choose from a list to grab all the files
[14:38] or grab a specific file you want but in
[14:40] this case it's going to be dynamic
[14:41] obviously based on what's coming through
[14:43] so we want to grab by ID and then this
[14:44] is where we can grab the file ID earlier
[14:47] that we set in order to um you know grab
[14:49] the right one and if we test up we
[14:51] should see the actual binary coming
[14:53] through of that um document and so now
[14:56] we see this binary information and
[14:57] that's how you know you got it right but
[14:59] also what we want to do here is ADD
[15:00] options Google file conversion and we
[15:03] want to convert Google docs to text you
[15:06] could also do PDF but we're going to do
[15:07] text here so as you can see right now
[15:08] it's coming through as binary which is a
[15:11] doc extension we test this again and it
[15:14] will come through as um text so if we
[15:16] view it we should see actual text
[15:17] information coming back rather than that
[15:19] binary okay we've got the text and now
[15:22] we actually want to extract that so
[15:23] we're going to grab an extract from file
[15:25] node we're going to go down to extract
[15:27] from text file which is right here here
[15:29] and basically just want to test the step
[15:32] and we should see that now it's coming
[15:34] back as actual data that we have in NN
[15:36] and then from here all we need to do is
[15:38] push that into the super base Vector
[15:40] store so we're going to add an option
[15:42] here we're going to type in super base
[15:43] and we don't want to do super base we
[15:45] want to do super base Vector store we'll
[15:47] use superbase later but for now we are
[15:49] just going to be doing add documents to
[15:51] Vector store we need to set up our
[15:53] credential once again um so we put that
[15:55] in there because we've already set that
[15:56] up we're inserting documents we are
[15:59] inserting documents to the table called
[16:01] documents and then for options you want
[16:03] to add options and then just leave that
[16:05] there um because it's just going to
[16:06] match the documents and it already has
[16:08] that function put in there so you don't
[16:09] need to touch it that's all we need to
[16:11] do and so obviously now we need to add
[16:13] our our our document loader so in here
[16:16] we're doing Json we're just going to
[16:18] load all data input and then for
[16:20] metadata this is where it gets important
[16:22] because we want to grab the actual
[16:24] metadata from or sorry we want to put in
[16:27] the file ID like I said so lat L we can
[16:29] reference it so if we go to schema we
[16:32] should be able to grab the set ID right
[16:33] here which is coming through Json file
[16:36] ID and actually this is not correct um I
[16:38] think I just need to update my my cloud
[16:40] instance but um when you put something
[16:44] Json dot whatever it is that means that
[16:47] it's going to reference whatever
[16:48] currently most previous node that it's
[16:50] coming from so this is trying to look
[16:51] for file ID within this extract from
[16:54] file which obviously that's not there
[16:55] all we have would be json. data so um
[16:59] actually let's see if we did json. dat
[17:02] it would come back with the the the
[17:04] project the text that we extracted so
[17:06] that's not what we want what we need to
[17:08] do is we need to get the file ID from
[17:10] this set ID node over here that we
[17:12] actually you know this is where we
[17:13] grabbed that file
[17:15] ID so in here typically you should be
[17:18] able to just drag stuff in and it should
[17:19] be fine I think this is just a bug right
[17:21] now because um it's going as
[17:22] Json so what we need to do is reference
[17:25] the nodes so in here we type in the
[17:27] curly braces we can see we have
[17:28] different noes
[17:29] we're looking we're looking through the
[17:30] set ID node and then within there now we
[17:33] want to look for the Json or actually no
[17:35] it should be item. Json
[17:38] dot move this so we can see do file
[17:42] ID okay now we can see we we're getting
[17:44] the actual file ID back and this is how
[17:47] we want it because now in the metadata
[17:49] of our super base we will see a file ID
[17:53] so um that should be good we've added
[17:55] metadata we want to add a recursive
[17:57] character text splitter um if if you're
[17:59] looking for more information about text
[18:00] Splitters then please go watch my end
[18:02] Master Class um I walk through sort of
[18:04] the difference between the three options
[18:06] that we have for text
[18:08] Splitters um and then our embedding once
[18:10] again we will be doing text embedding
[18:12] three small so at this point we have
[18:15] this first part of this workflow set up
[18:17] for when a new um file is created within
[18:20] our folder so if you you know we got a
[18:21] new project we WR wrote out a project
[18:23] brief and then we drag it into this
[18:25] folder called projects once this
[18:26] workflow is active up here it would
[18:28] automatically grab it and put it in so
[18:30] let's test this and then we should go
[18:33] back into our table which is right here
[18:36] it's empty um there we go it just popped
[18:38] through so now we have these three
[18:40] vectorization of this information as you
[18:42] can see um we've got like the the
[18:44] information right
[18:45] here and then if you go into the
[18:48] metadata each of these we should see a
[18:50] file ID so before it would have just had
[18:52] all this information The Source The Blob
[18:54] type but now we've um make sure that we
[18:57] put in file ID so that later we can
[18:59] reference it once again so we've got
[19:01] this also you can see the chat history
[19:04] um which is earlier we asked what our
[19:06] projects looking like and it was unable
[19:08] to get anything so we've got that and
[19:09] now we have data in there um and so you
[19:13] know we could go chat with this agent
[19:14] actually yeah let's just do that real
[19:15] quick we'll go back to the rag agent
[19:17] where we currently ask what they're
[19:18] looking like and now we will say give me
[19:21] an overview of project Mountain because
[19:24] that's the one we just put in there so
[19:26] now it will'll be obviously
[19:28] understanding our question question
[19:29] going to the database to grab that
[19:30] information it's retrieving it now it's
[19:32] generating an answer right here
[19:34] generating an answer and then we can pop
[19:35] back into here it's updating our
[19:38] um is it not going to be in here yeah
[19:40] there it is um it updated the chat
[19:42] history and now we see it's an AI power
[19:45] tool being developed by Summit
[19:46] Enterprises it's giving us goals
[19:47] features the team composition um all
[19:50] that kind of stuff and if we go back
[19:52] into super base we should see in our
[19:54] chat history once we
[19:56] refresh now we have this action we just
[19:59] had right here give me an overview of
[20:01] our projects or project mountain and
[20:02] then it gave us the
[20:04] overview so that's how that works and
[20:06] now we just need to set up the second
[20:07] part of this workflow which is going to
[20:09] be if a folder or if a file is um
[20:12] updated it will change the information
[20:14] so we're going to add a Google Tri a
[20:17] Google Drive trigger once again we'll go
[20:19] down to triggers and we'll want
[20:23] onchanges involving a specific folder
[20:25] once
[20:26] again same thing we're grabbing the same
[20:28] same folder and instead of watching for
[20:31] file created we'll just be looking for a
[20:32] file updated so let's real quick go in
[20:36] here and just say file
[20:39] updated we will come in here and just
[20:41] make this
[20:43] one new file so we understand what's
[20:46] going on in each one um let's also just
[20:48] organize this we'll call this this is
[20:50] the actual node that's
[20:52] downloading the file and then we've got
[20:55] extracting from file and then putting
[20:57] into Su base so
[20:59] yeah let's get working on this this
[21:01] workflow now so we've got our file
[21:03] updated
[21:05] um let's actually
[21:07] just no for now it's fine so we'll make
[21:09] a change later and we'll see but we
[21:11] fetched test event and it's going to
[21:12] grab project Mountain once again um from
[21:15] here what we want to do is grab a sub
[21:17] base and we're not doing Vector store
[21:18] this time we're doing actual sub base
[21:21] and so that we can delete a row within
[21:23] our table so we're going to set up the
[21:24] credential again we're going to be
[21:26] deleting a row we're going to be looking
[21:28] through documents um and then we want to
[21:32] build this as a string and now we have
[21:34] to type in how we want to make sure that
[21:36] it's how sub Bas should be looking for
[21:39] which rows to delete okay so in here um
[21:43] it's going to be sort of a filter but it
[21:45] might look a little little Cody so what
[21:47] we're doing is
[21:49] metadata because in
[21:51] subbase we're going to be looking
[21:52] through the metadata right here
[21:53] obviously and then in the metadata we
[21:56] want to look for oh sorry we're in chat
[21:58] history
[21:59] in the metadata of um these Vector
[22:01] vectorization we're looking through the
[22:02] metadata to look at the file ID so we're
[22:04] going to be saying like within metadata
[22:06] look for file IDs that equal this and if
[22:08] they equal that then delete them so
[22:12] metadata we're going to do a dash with
[22:13] two arrows um or greater than signs and
[22:16] then we're going to say file ID because
[22:18] that's what it's going to be looking for
[22:20] and then we're going to do equals sorry
[22:22] equals like period and then we're going
[22:26] to go with two asteris two stars and
[22:29] then change this to an expression and
[22:31] then whatever is going inside of these
[22:33] two stars is what it's actually looking
[22:35] for so we're going to once again we need
[22:38] to close down to grab the file ID of the
[22:40] document that it's looking for once
[22:42] again don't go to permissions ID we want
[22:44] spaces ID so we'll pull this in right
[22:47] here and it comes in it's just json. ID
[22:50] and it has the correct um information
[22:54] right there so all we're going to do is
[22:57] go back in here we see that there's
[22:59] three um rows that have that ID we're
[23:03] going to come back into here and then
[23:04] test the step and if we did this
[23:06] correctly we should get this this is how
[23:08] it should come back so that's good it
[23:09] has three items because it deleted all
[23:11] three of those those rows and now we
[23:13] switch back into super base you can see
[23:14] that they just disappeared so this is
[23:18] good now every time something's updated
[23:20] it's going to delete those old ones so
[23:22] that we can download the new file and
[23:23] then put the new file into superbase so
[23:26] that we're only interacting with ual
[23:29] accurate information so we'll save this
[23:33] next step here is that we want to grab
[23:35] the um the IDS so we're going to do
[23:38] another set node and once again we're
[23:41] just mapping out the actual file ID
[23:43] again so that we can reference it later
[23:45] at this point it's pretty repetitive so
[23:47] we're going to grab it call it file ID
[23:50] and then do right here so as you can see
[23:53] it's referencing the node called file
[23:55] updated because if it was just to do
[23:57] Json it would be looking for
[23:59] that's actually a great point if we just
[24:01] did json. ID Let's test this real quick
[24:04] so we can see it's pulling back the
[24:05] actual IDs but if we just did json. ID
[24:08] it would grab this ID right here so it
[24:10] would be grabbing the ID of the it would
[24:12] be grabbing basically the row ID of the
[24:14] vector um database so we don't want that
[24:17] so make sure you specify what node
[24:18] you're looking
[24:19] for and so now if you can see we have
[24:23] three items coming back because there
[24:24] were three rows so what we want to do
[24:27] here now is limit because we only want
[24:29] one to come back so all we need to do is
[24:31] one keep the first item test that now we
[24:33] have one ID coming back rather than all
[24:35] three um not sure if it's like
[24:38] completely necessary but it keeps things
[24:39] cleaner and then you're only trying to
[24:41] download like one file so that's why
[24:43] we're doing that um but anyways from
[24:45] there we want to actually download the
[24:48] file not download we want to grab a
[24:50] Google Drive node right here we're going
[24:53] to download that file and this is pretty
[24:56] much the exact same thing as the
[24:57] previous one with an
[24:59] ID and edit Fields we're grabbing in
[25:01] this file ID so perfect it's referencing
[25:04] the
[25:05] node and we'll hit test upep so now we
[25:08] can see the project Mountain this would
[25:10] be the updated folder or sorry updated
[25:12] file once again we want to do file
[25:14] conversion text run that again we should
[25:17] see the actual text coming through as we
[25:19] can see now it's a text folder or text
[25:21] file and now we've got this we also
[25:23] could have easily just copy and pasted
[25:24] this node down here which probably would
[25:26] have been the smarter thing to do but
[25:29] um nobody's perfect so anyways download
[25:31] file
[25:33] two so we've got this and then it's the
[25:36] exact same thing so we can this time
[25:37] we'll just copy and paste this node down
[25:39] here to extract from a text file um
[25:41] we'll run that we can see the
[25:43] information coming through and then
[25:45] honestly I think this also can just be
[25:47] duplicated as well because we're just
[25:50] doing the exact same thing as long as we
[25:52] have um this is the only thing I think
[25:53] we need to change
[25:56] so um
[25:58] we're grabbing it from let's see okay so
[26:01] we just want to call
[26:02] this set ID
[26:05] 2 and so this one right now is looking
[26:08] through a node called set ID which
[26:10] obviously there's no information there
[26:11] because it's looking through this one so
[26:12] now we need to make it say in this case
[26:15] you'll be looking through set ID number
[26:16] two so if we come in here and we just
[26:18] add a number
[26:19] two we should be fine um can't determine
[26:23] which item to
[26:25] use maybe it's just because it hasn't
[26:26] ran let's okay let's try something we'll
[26:29] run
[26:30] this and now there's an error
[26:33] okay let's just try it again we'll do it
[26:35] manually
[26:37] so anyways why is it doing that why is
[26:42] it doing that
[26:43] okay bear with me here okay so now we're
[26:45] grabbing set
[26:47] id2 it's working so what do we do item
[26:50] Json file
[26:54] ID no do we not name it the same thing
[26:58] file _ ID oh okay maybe it's because we
[27:01] want to maybe grab it from limit because
[27:03] it's just limiting one let's try
[27:06] that why does it do that when I
[27:08] okay delete that we're going to go from
[27:12] limit and we can just maybe say
[27:16] item.
[27:18] json. file ID okay perfect there we go
[27:21] now we're getting the correct ID back
[27:23] that we want to put into the metadata
[27:25] once again um we'll hit save and now
[27:28] we'll run this again although yeah so
[27:31] there's nothing in there right now we
[27:32] run this again and we should see um
[27:35] three new vectors pop into there let's
[27:37] go and see if we can see it
[27:39] live um we might just have to give it a
[27:44] refresh yeah we'll give it a
[27:46] refresh there we go so we've got these
[27:49] um three new Vector stores so the first
[27:50] ones were one two three deleted those
[27:52] now we have
[27:53] 456 and we can see in here we' got the
[27:55] metadata so it's all working as it
[27:57] should
[27:58] um and this is really it so one thing I
[28:00] wanted to mention is you know ideally
[28:02] you would also
[28:03] have some sort of you know a node down
[28:06] here where let me just show you so a
[28:10] cool option would be if you wanted to
[28:13] have another trigger down at the bottom
[28:14] which is going to be changes involving a
[28:16] specific folder You' grab that same
[28:19] folder um once this loads
[28:21] up I think I'm overwhelming my computer
[28:24] with with um super base information
[28:28] but um let's see we grab a
[28:31] folder anyways my point was it'd be cool
[28:35] if there was like a file removed file
[28:36] deleted that way you could just you know
[28:38] delete folders once a Project's done but
[28:41] also maybe it's good to give a summary
[28:43] of like a project that's done or
[28:44] whatever it is but there's probably use
[28:45] case where you wanted to remove stuff so
[28:48] in that case you'd have to probably
[28:49] manually go into your super base delete
[28:52] those vectors you could also just update
[28:54] your file and say like this project has
[28:56] concluded or this is no longer relevant
[28:58] or whatever it may be and it would
[28:59] obviously update that but the point
[29:02] would be you you'd grab the ID and then
[29:03] you just have a super based thing to
[29:05] delete it and then it would just
[29:06] literally just be those two nodes so it
[29:07] would be like a delete row down here and
[29:11] then maybe like a you know at the end of
[29:13] these you could have a
[29:14] notification you could at the end of all
[29:16] of these workflows have a notification
[29:17] that said like okay new file was created
[29:19] and added to subbase and then it would
[29:21] just like text you that same thing over
[29:23] here blank was updated and deleted and
[29:26] then reuploaded to superbase and then
[29:28] down here was like project Mountain was
[29:30] deleted from superbase so you could
[29:31] always you know add some more stuff off
[29:33] of this and this one would just delete
[29:35] the file and then that would all all it
[29:36] would do but I guess a workaround for
[29:40] this could be you could have like a node
[29:42] that is always running to compare the
[29:44] files or the folder and then you would
[29:46] just see if like a comparison doesn't
[29:48] match up with this one then it would
[29:49] delete whatever like isn't syncing from
[29:51] superbase so that would be like just a
[29:53] quick workaround but um maybe in the
[29:55] future they'll have just an integration
[29:56] in Google Drive where you can just just
[29:58] do that right away so anyways we're
[30:00] going to make this workflow active and
[30:02] we're going to test out some stuff
[30:04] so got it so this workflow is now active
[30:06] it should be looking for within this
[30:09] folder right here if anything new is
[30:10] added so I'm going to make a new
[30:12] document real quick We'll add it in
[30:13] there and then we'll watch the execution
[30:15] happen Okay we're back with a new one
[30:17] this one's called project snow um we
[30:20] were going to put this one into the the
[30:22] folder I don't know if you can tell but
[30:24] um yeah it's almost winter and I'm
[30:26] looking forward to skiing so that's
[30:27] what's top of mine but anyways project
[30:29] snow right here we're GNA drag that into
[30:31] projects so now in this folder we have a
[30:34] folder or we have a new file just got
[30:36] created just got put into the the what's
[30:38] it
[30:39] called the folder so here's that
[30:41] execution we grabbed in here um project
[30:45] snow which should be I always have a
[30:47] hard time finding this anyways we'll go
[30:49] to
[30:50] Json project snow I might have scrolled
[30:53] too far once again sorry about that um
[30:56] you know what never mind we we'll see it
[30:57] we'll see it later so set ID downloads a
[31:01] file extracts from file now we can see
[31:02] the the project briefest project snow
[31:04] and then it got put into super base
[31:06] we'll come in here refresh this we
[31:09] should see 789 so now we've got um these
[31:12] new ones with their unique IDs in there
[31:15] um so yeah let's go over to the rag
[31:17] agent and we will talk to um the agent
[31:19] about project snow we'll
[31:22] say um what is Project Snow's budget
[31:28] that's simple enough we'll come in here
[31:30] and see that the Project's snow budget
[31:32] is 30,000 so that was obviously a very
[31:35] simple use case um there we go project
[31:38] snow budget is 30,000 so let's go back
[31:40] into project snow let's change the
[31:43] budget
[31:44] to um let's just say we have no money so
[31:50] now we we've changed
[31:52] this we will go to the project folder
[31:55] refresh that and we should see now it
[31:57] just got ified and we will go back into
[32:01] here and wait for another execution to
[32:03] come through of the um the updated
[32:08] file okay so as you can see it's running
[32:10] right now um we'll take a look at that
[32:12] in a sec so it already succeeded let's
[32:14] click into this and now we can see it
[32:16] went through the file updated path it
[32:18] would have deleted this old record
[32:20] uploaded the new one and let's look at
[32:22] sub base sorry I was about to drink
[32:23] water and then it happened but let's go
[32:25] look into sub base and see what happened
[32:27] okay so originally we put project snow
[32:28] into here they were IDs 789 as you can
[32:31] see 789 was deleted and it was replaced
[32:32] with 10112 and they still have our file
[32:35] IDs in there so now we should be able to
[32:37] go back into the rag agent and say
[32:41] um what is the budget
[32:45] now and it should say something about
[32:47] that we have no money which is
[32:48] unfortunate but you know at least we
[32:51] know we're getting accurate information
[32:52] the current total oh sorry it's looking
[32:54] for all so what is the budget
[32:58] for project snow so that this would
[33:01] probably have to do with you know
[33:02] prompting and the way that we have the
[33:03] memory set up because you would assume
[33:05] that it would know that it's referencing
[33:06] project snow but I don't currently have
[33:08] any access to specific budget details
[33:10] for project snow if there's anything
[33:11] else you'd like to know or other
[33:12] projects you're interested in let me
[33:13] know so let's see if we can actually
[33:15] look at what came back from superbase so
[33:18] the system says use the following pieces
[33:19] of context to answer the user's question
[33:21] it's pulling information about products
[33:22] know if you don't know the answer just
[33:24] say that you don't know don't try to
[33:25] make up an answer so that's how you can
[33:26] um you know try to limit that
[33:27] hallucination but then at the bottom you
[33:29] can see budget we have no money so
[33:31] that's why it came up with this answer
[33:32] just basically saying we don't have
[33:34] specific budget details but yeah that's
[33:36] about it for this one hopefully you
[33:37] found this valuable as far as looking at
[33:38] you know super base and post guest if
[33:40] you haven't explored these tools before
[33:42] um also you know the workflows will be
[33:43] downloadable in the free school
[33:46] Community Link for that down in the
[33:47] description if you're interested in
[33:48] going a little farther and getting some
[33:49] more Hands-On learning please um reach
[33:51] out to me about the paid Community we'd
[33:52] love to have you in there um see you on
[33:54] some live calls stuff like that and then
[33:56] once again if you're looking for help
[33:57] actually implementing these sort of
[33:58] solutions into your business or if
[34:00] you're run an agency that sort of stuff
[34:02] please reach out book a call on my
[34:03] website and let's talk about how we can
[34:05] work together but thanks for watching
[34:07] this one that's all I've got um hope you
[34:09] guys found this one valuable of course
[34:10] and I will see you guys in the next
[34:12] video