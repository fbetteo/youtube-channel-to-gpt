Video Title: Build Anything with GPT-5 and n8n AI Agents
Video ID: gGCwSIlIRlY
URL: https://www.youtube.com/watch?v=gGCwSIlIRlY
View Count: 74,823

[00:00] So, OpenAI just dropped GBT5, which has
[00:02] taken the internet by storm today. It's
[00:04] been all over my LinkedIn, my ex,
[00:05] whatever I'm looking at. All I see is
[00:07] GBT5, and I see that it is killing all
[00:09] the other models in stuff like coding.
[00:11] So, of course, what I'm going to do
[00:12] today is break down these benchmarks and
[00:14] talk about why you need to switch out
[00:15] GBT5 for all of your AI automations in
[00:18] NAND specifically. So, of course, I'm
[00:20] also going to get into NADN. I'm going
[00:21] to show you guys how to build a GPT5 AI
[00:24] agent. And then we're actually going to
[00:25] run a few experiments so I can show you
[00:26] guys just how good this is with NAND AI
[00:29] agents. So, let's get started. So, like
[00:31] I said, why we are here today is not
[00:32] just to talk about GBT5, which is
[00:34] OpenAI's new model, but to relate it
[00:36] back to Naden since that's kind of what
[00:38] this whole channel has been about so
[00:39] far. So, I just wanted to start off with
[00:40] a quick overview of this GBT5 release.
[00:42] Today's August 7th, and that is when it
[00:44] was dropped. As far as availability,
[00:46] OpenAI made this available for all
[00:48] ChatGBT users, including free and paid
[00:50] tiers. So, if you go into your CHAGBT,
[00:52] it's going to be all pretty. It's going
[00:53] to say GBT5 is here, and it's pretty
[00:55] cool. But what is GBT5? Of course, it's
[00:58] the latest model and it's super super
[00:59] powerful. An upgrade from the other GBT
[01:01] models that excels in reasoning, coding,
[01:03] handling images, answering questions
[01:05] safely and more accurately than previous
[01:07] versions. And down here, I've got a cool
[01:08] quote from Sam Alman. He said that GBT3
[01:10] felt like talking to a high school
[01:11] student. Four felt like talking to a
[01:13] college student, but five is the first
[01:15] time that it really feels like talking
[01:17] to an expert in any topic, like a PhD
[01:19] level expert. So, that's pretty
[01:21] powerful. We'll have to see for
[01:22] ourselves. And so with this release,
[01:24] similar to other families of GPT models,
[01:27] five came with a few other ones. So
[01:29] we've got mini and nano, and it also
[01:31] came with Pro, which I think might only
[01:32] be available for paid users, but it's
[01:34] pretty much just an extended version of
[01:36] GBT5 with more reasoning. But if you're
[01:38] taking a look at the actual price, so
[01:40] this is based on input and output
[01:42] tokens, and it's based on per million.
[01:44] So GBT5 is $1.25 per million input
[01:47] tokens, and GBT40 was double that, even
[01:50] though they're the same price for
[01:51] output. But you can see the mini and the
[01:53] nanos are extremely cheap. So if the
[01:56] mini is anywhere as good as, you know,
[01:59] GPT 4.1 mini, which has honestly been my
[02:01] go-to for anyone AI agents so far. So if
[02:04] the mini is just as good or better,
[02:05] which I assume it will be better, but
[02:07] much much cheaper, then it's an absolute
[02:09] no-brainer to switch it out for all of
[02:10] your AI automations. Of course, you
[02:12] probably want to switch it out in a test
[02:13] environment just to make sure you're all
[02:14] good. But still, I'm probably going to
[02:16] be switching all of mine over. So, I
[02:18] won't dive into these previous model
[02:19] prices, but you can see it's a lot lot
[02:21] cheaper. And the key takeaways here,
[02:23] GBT5 is about half the input cost of
[02:25] GBT40. The mini and nano versions of
[02:28] GBT5 make advanced AI even cheaper, well
[02:30] below previous versions. And pricing for
[02:33] these GBT models just seem to come out
[02:34] and drop more and more every single time
[02:37] there's a new family. So, it's pretty
[02:38] cool to see where we're headed. And of
[02:40] course, I wanted to show you guys some
[02:41] actual benchmarks, but I don't just want
[02:43] to throw some graphs at you. And there's
[02:45] all these fancy names for benchmarks
[02:46] like S. or like Ali or I don't even that
[02:49] could be false but we're going to
[02:51] actually explain what they mean. We're
[02:53] not going to look at every single one of
[02:54] them but we will look at some of the
[02:55] cool ones. So here is the SWE bench
[02:57] which is kind of like a software
[02:59] engineering exam. GBT5 scored almost a
[03:02] 75% on this benchmark which means it can
[03:05] correctly solve nearly three out of
[03:06] every four real world coding problems
[03:08] pulled straight from GitHub which makes
[03:10] it the most accurate AI for these sorts
[03:12] of programming tasks to date. In this
[03:15] graph, you can see here in the pink is
[03:17] GBT5. And then right here was OpenAI's
[03:19] reasoning model 03, which at the time
[03:21] was really, really good. But GBT5 does
[03:23] even better. This next one is called the
[03:25] Ader Polyglot, which is a multi-
[03:27] language code editing exam. GPT5 got an
[03:30] 88% on this benchmark. And this is
[03:32] significant because it means that GBT5
[03:34] can accurately handle almost nine out of
[03:36] 10 real world code editing tasks, which
[03:38] sets a new record and shows a huge leap
[03:41] in reliability and usefulness for
[03:42] developers compared to earlier AI
[03:44] models. Here's another one that's pretty
[03:46] cool. And by the way, you can see all of
[03:48] these benchmarks if you go to OpenAI and
[03:50] just look at the release notes for this
[03:52] model. But they showed these three
[03:53] examples of here is a oneshot prompt.
[03:55] Oneshot meaning you gave it basically
[03:57] like two sentences of a prompt and that
[03:59] was it. and you didn't like iterate back
[04:00] and forth. And it created this whole
[04:02] like landing page and and site which
[04:04] looks really really clean. It created
[04:06] this like audio step sequencer where you
[04:08] can play with the different things and
[04:10] hit play and different sounds and make
[04:11] music. And then this full like spaceship
[04:14] game that I was in there playing and um
[04:16] apparently all of that was one shot.
[04:18] Obviously there's a lot of code going on
[04:19] in the background, but also a lot of
[04:21] design elements and UI elements as well.
[04:23] And there's a lot of benchmarks. I'm not
[04:25] going to throw too many more at you
[04:26] guys, but just to bring up these ones
[04:27] real quick. These images show that GBT5
[04:30] is much better than earlier AI models at
[04:32] following different types of
[04:33] instructions correctly, which is
[04:34] relevant to, you know, prompting our
[04:36] agents in NIDN. In simple terms, GBT5
[04:39] apparently can understand and do what
[04:41] you ask more accurately. Another one
[04:43] that's relevant to our NEN AI agents is
[04:45] this benchmark right here, which shows
[04:47] that it is a more accurate model at
[04:49] using external tools compared to other
[04:52] models. And finally, I just wanted to
[04:54] show these two cuz these are also pretty
[04:55] cool. The first one is long context. You
[04:57] can see GPD5 ranks the highest here and
[04:59] that's very important if you're having
[05:01] agents that are kind of stacking up, you
[05:02] know, multiple conversations and have to
[05:04] look at a ton of stuff in order to, you
[05:06] know, create content or take action,
[05:07] whatever it is. And then over here, we
[05:09] saw a huge improvement in factuality so
[05:11] you can actually know that they're
[05:13] giving you the correct answers. So, how
[05:15] does GBT plus NADN revolutionize
[05:18] automation? Well, smarter automation
[05:20] because the accuracy means that
[05:21] businesses can safely automate tasks,
[05:24] whatever they are, reducing errors and
[05:26] trust that the systems are working
[05:28] correctly. We've got all-in-one power.
[05:30] GBT5 can handle text, images, code, and
[05:32] complex workflows in one platform. And
[05:34] in NAD, we can set up these super custom
[05:36] automations that are powered by GBT5 to
[05:39] handle that kind of stuff. It's very
[05:40] accessible. This stuff is getting easier
[05:42] to use with NADN, the visual building,
[05:44] stuff like that. And the models are
[05:45] getting cheaper and cheaper. And as far
[05:46] as the industry impact, faster, safer
[05:48] processes in healthcare, marketing, IT,
[05:50] and education frees up teams to focus
[05:52] more on creative and strategic work. So
[05:55] today, we're going to switch over to
[05:56] NIDAN, and I'm going to show you guys
[05:57] four things. The first one is we're
[05:59] going to connect to a GBT AI agent in
[06:01] NIAN. The second one is we are going to
[06:03] do an actual evaluation using NIDN's
[06:05] evaluation feature and see the direct
[06:08] results from a GPT5 compared to a
[06:10] different model that we'll choose. Then
[06:12] I'm going to plug in GBT5 to my Ultimate
[06:14] Assistant and just give it a loaded
[06:16] prompt and see if it can call all the
[06:17] tools and how well it does it. And then
[06:19] we're going to do some image prompt
[06:20] generation with GBT5 and compare the
[06:22] image to a different one. So this last
[06:24] one's kind of more for fun, but I know a
[06:26] lot of you guys are using NAND for
[06:27] content generation. So I thought this
[06:29] would be applicable. So real quick going
[06:31] to show you guys how to connect to GBT5
[06:33] in NADN in case you haven't done it
[06:35] before. So what I'm going to do is I'm
[06:37] going to pull in an AI agent. And when
[06:39] we have an AI agent, we're able to talk
[06:41] to it if we open up this chat window
[06:42] down here. And so if I say, "Hey,"
[06:45] nothing's going to happen because we
[06:46] don't have an actual AI model attached
[06:48] to the agent to talk back to us. So I'm
[06:51] going to click on the plus for the chat
[06:52] model. And I'm just going to scroll all
[06:53] the way down on this right hand side to
[06:55] open AI chat model. And this is going to
[06:57] prompt you to go to OpenAI and get an
[06:59] API key. I'm just going to do that real
[07:00] quick in front of you guys. So I'd open
[07:02] this up and I'd click on create new
[07:03] credential. We need an API key. And what
[07:06] you're going to do is go to openai.com.
[07:08] Here you can see the release of GBT5 and
[07:11] when you go to log in you can see that
[07:12] you have the option for chat GBT or the
[07:15] API platform and that API platform is
[07:17] what you need to go to. It's different
[07:19] than your chat GBT account. Once you get
[07:21] into your API platform you'll go to your
[07:22] dashboard and then you can see on the
[07:24] lefth hand side API keys. All you need
[07:26] to do is click on create new secret key.
[07:28] We'll call this one GBT 5 test. You can
[07:32] call it whatever you want. And then it's
[07:33] going to give you a secret key and
[07:34] you'll copy this value. You'll go back
[07:36] into end. You'll paste that right here.
[07:38] And when you hit save, you are now
[07:40] connected to your NADN instance. Just
[07:42] keep in mind, it's not going to work
[07:44] unless you do have billing information
[07:46] in your API dashboard. Even if you're on
[07:48] the paid 20 bucks a month chatbt plan,
[07:50] you still need to put in money for API.
[07:53] And now that we've connected that
[07:54] credential, we actually have to choose
[07:55] our model. So, I'm just going to come
[07:56] into this model list, type in GBT-5,
[07:59] and we should see it pop up right here.
[08:01] We can see all the other ones as well.
[08:03] I'm just going to do straight up five
[08:04] for now. And now I can just say hello
[08:07] and it will respond to us using chat GBT
[08:10] 5. So now that we've got that figured
[08:12] out, what I'm going to do is do the
[08:14] actual evaluation now. And this is going
[08:16] to look a little bit different because
[08:17] we're going to use Open Router instead
[08:19] of OpenAI. Open Router is basically a
[08:21] platform that just lets you connect to
[08:22] tons of different models through one.
[08:24] And I like it because I can have all my
[08:25] billing information in one account
[08:27] rather than one for Anthropic, one for
[08:29] OpenAI, one for Google, all this kind of
[08:30] stuff. But it' be the same thing. You'd
[08:32] come here and you'd get an API key and
[08:34] you'd create a credential the same way.
[08:35] But you can see that Open Router lets us
[08:37] use OpenAI's new models. So anyways, we
[08:39] are going to run two evaluations here.
[08:41] And if you are kind of confused about
[08:43] the concept of evaluations, it may look
[08:45] a little confusing, but at the end
[08:47] you'll see exactly very explicitly which
[08:49] model performed better. But I do have a
[08:51] full video that will be coming out soon
[08:52] about evaluations. So stay tuned for
[08:53] that. But anyways, the first evaluation
[08:55] that we're going to run, we're not going
[08:56] to do GPT5 to start. Let's just do GPT4.
[09:00] Actually, I'm at GBD40, which is two
[09:02] times as expensive for input tokens, but
[09:05] same for the output. So, we're just
[09:06] going to start with this one. And now
[09:07] I'm going to go to the evaluation tab
[09:09] and hit run test. So, what this is
[09:10] currently doing is it's sending through
[09:12] 10 rows of our test data. And we have an
[09:16] expected answer. And then our agent's
[09:18] creating an actual answer that would
[09:19] have happened in production. And the
[09:20] evaluation is going to actually show us
[09:22] the accuracy of these answers compared
[09:25] to what we were expecting. So, I'll
[09:26] check back in when this one's done.
[09:28] Okay. Okay, so that just finished up
[09:29] with GPT40 and we can see stats like the
[09:32] tokens and the execution time and the
[09:34] accuracy here was 4.2. So now what I'm
[09:36] going to do is go back into the editor.
[09:38] I'm going to come into our actual agent
[09:40] that's doing the lookup in our vector
[09:42] database and creating the email to go
[09:44] back out and I'm going to switch this to
[09:46] GPT5 and we're going to run that
[09:48] evaluation again and hopefully it comes
[09:50] back cheaper and more accurate. Okay, so
[09:53] GPT5 just finished up. It ended up using
[09:55] more tokens. So, I'm going to do the
[09:56] math here in a sec and see if it
[09:57] actually was cheaper or not. It took a
[09:59] lot longer, but the sacrifice there was
[10:02] that it was 4.7 accuracy. And I have a
[10:04] feeling if the test data was more than
[10:06] just 10 rows, it would have been even
[10:08] more accurate. But one thing that's like
[10:10] subjective is when I was personally
[10:11] reading through the actual email
[10:13] responses compared to 40, these were far
[10:15] better. They're a lot more detailed and
[10:17] they're even a lot more personal and
[10:18] they feel more human. So, so far, I'm
[10:21] still thinking GBT5 is the winner here.
[10:23] So just for fun, I decided to do another
[10:25] run with GBT5 mini. And while I was
[10:28] sitting here, I also thought about the
[10:29] fact that because GBT5 is so good at
[10:31] coding and we've been seeing people use
[10:33] like clawed opus 4 to generate edit in
[10:35] workflows, you know, that's JSON coding.
[10:38] Um, I think that GBT5 would probably do
[10:40] better at it. So I'm sure there'll be
[10:42] some YouTube videos coming out and maybe
[10:44] I'll even do something. But something to
[10:45] think about GBT5 for troubleshooting nin
[10:48] workflows and for generating code for
[10:50] your Nin workflows could be pretty
[10:51] solid. And also something I did want to
[10:53] say is with GBT5, it could be a lot
[10:56] slower right now because it's new and
[10:58] everyone in their mothers is trying to
[11:00] test it out. So that could be another
[11:02] variable here of why GBT5 is a bit
[11:04] slower. Okay, so here we have the final
[11:06] standings. GBT5 was this one in the
[11:08] middle. It did the best by far with
[11:10] accuracy. It took the longest and also
[11:13] I've got the prices right here. So GPT5
[11:15] was about 22 cents for all 10 of these
[11:18] runs, which was more expensive than
[11:19] GPT4. It actually came out to being
[11:22] almost double the price. And you can see
[11:24] the reason why it was so much more is
[11:25] because GBT5 was generating a lot more
[11:27] output and the output token cost is the
[11:30] same as the output token cost for 40.
[11:32] But if you look at the input tokens, you
[11:33] know, it was half the price. So that is
[11:35] something to keep in mind. If you are
[11:36] doing something where it's tons and tons
[11:38] of output, GBT5 won't be much cheaper
[11:40] than 40. But of course, 40 was less
[11:42] accurate. So that's usually something
[11:44] you do want to prioritize. Obviously,
[11:45] the goal is to find the best balance of
[11:47] speed, cost, and accuracy. And then with
[11:50] GBT 5 mini, it didn't do great here.
[11:52] This was a 3.6 accuracy, but obviously
[11:55] if you look at the cost, it was about 3
[11:56] cents, which is a fraction of the other
[11:58] ones. And I know these may look like bad
[12:00] accuracy scores. They're out of five, by
[12:02] the way. I should have said that way
[12:03] earlier, but um if you look at the
[12:06] actual experiment, there's no system
[12:07] prompt in here. So, this agent basically
[12:09] just receives an email and it has tools
[12:11] and it just kind of has to figure stuff
[12:13] out. And that's what I wanted to isolate
[12:14] just the model selection and not have
[12:16] any prompt variables be coming into play
[12:18] here. Like I said, I'll have a video
[12:19] coming out soon about evaluations if
[12:21] you're interested in that. Not going to
[12:22] dive into it now, but let's move into
[12:24] the next test. Okay, so this is Ultimate
[12:27] Assistant. It's got lots of tools here,
[12:29] and that's what I want to check is if
[12:30] GPT5 is good at, you know,
[12:33] understanding, reasoning, following
[12:35] instructions, and then also ultimately
[12:37] tool calling. So, it's a pretty loaded
[12:39] prompt. It's going to have to use a lot
[12:40] of different tools here and probably use
[12:42] the tools kind of multiple times. So,
[12:44] we'll see how it goes. Oh, there it
[12:46] goes. It just hit Tavly. It's hitting
[12:47] Plexity, hitting the contact agent, and
[12:49] then it's going to have to hit both the
[12:50] email and the calendar agent as well.
[12:52] All right, so it looks like it's
[12:53] finishing up right now. It's taken about
[12:55] 3 minutes. I think there's a mix of GPT5
[12:59] doing a lot of thinking and reasoning,
[13:00] but also a bit of, like I said earlier,
[13:02] people just spamming the server right
[13:04] now, which is why I think it's a little
[13:05] slower, but looks like it did everything
[13:07] perfectly. Obviously, we'll go take a
[13:09] look at the research it did and the
[13:11] actual content it created. I just pulled
[13:12] up my calendar right here. So, while I
[13:14] just drag this in, you can see there is
[13:15] a dinner at 7 p.m. with Michael Scott
[13:18] and it has the correct email that is in
[13:20] my contact database. Okay. And also, it
[13:22] told us that perplexity search worked,
[13:24] but it tried Tavi twice because there
[13:26] was an authentication error. And I
[13:28] realized that in here I have my wrong
[13:29] Tavi API key. So, it handled that error
[13:32] pretty swiftly. It tried again and then
[13:34] it realized, okay, this isn't something
[13:35] that I'm going to be able to fix. We saw
[13:37] the calendar event. Let's go real quick
[13:38] look at the email. Okay, here it is. It
[13:41] was to dextermiami.com, which is the
[13:43] correct email. And look at this. This is
[13:44] pretty solid considering we didn't run
[13:46] this through a different AI that's
[13:48] prompted on how to send emails or create
[13:50] like a, you know, a blog post type of
[13:51] thing. It just sent this based on what I
[13:54] said. We have key features right here,
[13:55] which are a ton. We have availability
[13:57] and pricing. We've got a table here,
[13:59] which is pretty cool. And then at the
[14:01] bottom, it sent us these five sources.
[14:03] So, that's pretty cool. Like I said,
[14:04] this didn't run through any sort of
[14:06] system prompt for it to know to do this.
[14:08] So, that's pretty solid. And I just
[14:10] wanted to come in here and showcase a
[14:11] little bit of the reasoning and tool use
[14:13] functionality. Let's move on to our
[14:14] final test, which is image generation,
[14:16] comparing GBT5 with a different model.
[14:19] Okay, so we've got a simple agent here
[14:21] set up with GBT5, and it's going to
[14:23] create an image prompt for OpenAI's
[14:25] image generation. So, I'm going to send
[14:26] this one off right over here, which is
[14:28] going to GBT5, and I'm going to send off
[14:30] the exact same prompt in a different
[14:31] tab, but this time we're going to use a
[14:33] different model. So, let me choose,
[14:34] let's just do GPT40 again, since we
[14:36] compared that earlier. So, as you can
[14:37] see, we have GBT40 in here. I just saved
[14:39] it, and we're going to send off the
[14:40] exact same prompt. And then once both of
[14:42] these images are finished up, I will let
[14:44] you guys know. As you can see, they're
[14:45] both being generated right now. And once
[14:47] again, just to limit the variability,
[14:49] there's no prompt in the actual agent
[14:51] about how to create an image prompt. I
[14:53] just basically gave it this user message
[14:55] that you guys saw me send off. Okay, so
[14:57] these both just finished up. Let's first
[14:59] take a look at actually, let's take a
[15:01] look at GPT4's first. So, this is the
[15:03] one with 40 O's. As you guys can see,
[15:04] I'm going to open up this binary fire
[15:06] right here, and we'll take a look. Okay,
[15:08] not bad. It is a crocodile wearing
[15:10] sunglasses on a motorcycle. It looks
[15:12] pretty decent. Now, let's flip over to
[15:14] GPT5. As you guys can see right here,
[15:16] GPT5 and the moment of truth. Let's open
[15:19] up this image.
[15:21] Okay. I mean, that's pretty cool. I
[15:23] think I mean, you know, honestly,
[15:24] they're both solid. If you take a look
[15:26] here, this one, I think, definitely is
[15:29] better. Um, but this is all subjective,
[15:31] right? The point is they both could do
[15:33] it and the point is that they weren't
[15:35] prompted on how to create hyperrealistic
[15:37] images or whatever. All they both got
[15:38] was the same exact input. And I
[15:41] personally do like GBD5s better, but
[15:44] like I said, subjective. Anyways, that's
[15:46] going to do it for today's video. If you
[15:47] guys enjoyed this type of content and
[15:49] you want to dive a little bit deeper
[15:50] with NIDAN automations and stuff like
[15:51] that, then definitely check out my plus
[15:53] community. The link for that will be
[15:54] down in the description. We've got a
[15:56] great community of members who are
[15:57] building with NIN every single day. I
[15:58] think a lot of the conversations today
[16:00] were around GBT5 job. But besides that,
[16:03] we have a full classroom section with
[16:05] two courses. Agent zero, which is the
[16:07] foundations for AI automation, and then
[16:09] 10 hours and 10 seconds where you learn
[16:10] how to identify, design, and build
[16:12] time-saving automations. We also are in
[16:14] the middle of our first monthly
[16:16] hackathon, which is really cool. This
[16:17] month is voice agents, and we're going
[16:19] to be building some really cool stuff
[16:20] every single month. So, I'd love to see
[16:22] you guys in these communities. But
[16:24] that's going to do it for today. If you
[16:25] enjoyed the video or you learned
[16:26] something new, please give it a like. It
[16:28] definitely helps me out a ton. And as
[16:29] always, I appreciate you guys making it
[16:30] to the end of the video. I'll see you on
[16:32] the next one.