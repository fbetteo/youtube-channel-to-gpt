Video Title: 6 Months of Building AI Agents in 43 Minutes (without the hype)
Video ID: BhGaGFH0jR4
URL: https://www.youtube.com/watch?v=BhGaGFH0jR4
View Count: 56,963

[00:00] today I want to talk about a gentic rag
[00:02] the conversation around rag seems to be
[00:04] shifting so fast with you know different
[00:06] models releasing larger context Windows
[00:08] where does the future of rag really lie
[00:10] we've heard KAG we've heard graph rag
[00:12] we've also heard atic rag so just wanted
[00:14] to come in here and break it down and
[00:16] make sure you stick around to the end of
[00:17] this one because I'm going to be hopping
[00:18] into end at end and looking at a super
[00:20] cool template for agentic rag so before
[00:23] we start talking about agentic rag real
[00:24] quick just got to understand what rag is
[00:27] stands for retrieval augmented
[00:28] generation and essentially it's just the
[00:30] process of you know giving your agent
[00:32] access to some sort of database in order
[00:35] to retrieve information based on the
[00:37] query that you ask it it's going to get
[00:38] back that context augment it with the
[00:40] original query and then generate an
[00:42] answer that is detailed and specific to
[00:44] what you asked the simplest way I like
[00:46] to think about it is let's say someone
[00:47] asks you a question like what's the
[00:48] capital of Illinois and you don't know
[00:50] you'll take that query that they asked
[00:52] you you'll do something like you'll
[00:53] Google it look at the results and then
[00:55] you'll answer them um one misconception
[00:58] I feel like is when we hear rag we
[00:59] immediately think of like a vector
[01:00] database which that is rag however more
[01:04] broadly the term of rag just kind of
[01:06] refers to grabbing context from
[01:08] somewhere else and pulling it back to
[01:09] make an answer so how does this work
[01:11] with traditional rag let's talk about
[01:13] the most common use case of a vector
[01:15] database so down here we have a bunch of
[01:17] documents in this case we're just
[01:18] looking at one but let's say we have a
[01:20] ton of documents that are text what we
[01:22] have to do is we have to somehow get
[01:23] these into a vector database so how this
[01:25] works is the document is split up into
[01:27] chunks and this is something that we can
[01:29] play around and test with as far as
[01:31] different chunk sizes and different
[01:32] chunk overlaps but in general it's going
[01:34] to get turned into chunks so right here
[01:36] we can see we have made three chunks out
[01:38] of this one document from there those
[01:40] chunks get run through an embeddings
[01:42] model which is basically just turning it
[01:45] into a numerical representation of data
[01:47] so that it fits somewhere within our
[01:48] Vector database which is uh
[01:51] multi-dimensional representation of data
[01:53] where the vectors or each of these
[01:55] little points or dots are stored
[01:57] somewhere in this space based on the
[02:00] Dimensions they're given when they run
[02:02] through this embeddings model now the
[02:04] dimensions are basically just a bunch of
[02:06] numbers and these numbers actually are
[02:08] associated with contextual meaning based
[02:10] on the words that are in this chunk so
[02:13] let's say you know this chunk is
[02:14] associated with company information so
[02:16] it goes up here this chunk is associated
[02:18] with Finance information so it goes over
[02:20] here and then this chunk is associated
[02:23] with marketing information so it goes
[02:24] down here and they're all placed
[02:25] differently in this Vector database and
[02:27] they'll all be kind of Shifting as more
[02:28] information's flooded in so that all of
[02:30] the vectors that are associated with
[02:32] each other and relevant to each other
[02:33] are near each other all right now when
[02:35] it comes to us actually wanting to query
[02:38] that Vector database we usually use an
[02:40] agent in order to get that aspect of rag
[02:43] so this is what the process looks like
[02:45] um I tried to make it as visually simple
[02:46] as possible but what it starts with is a
[02:49] trigger which is usually us asking a
[02:51] query to an agent so let's say in this
[02:53] example we're asking what is company X's
[02:55] mission statement the agent will then
[02:57] read that question it will turn it into
[02:59] its own query to send off to the vector
[03:01] database so in this case it just says
[03:02] company X mission statement and then
[03:04] that query gets embedded using the exact
[03:07] same embeddings model that happened up
[03:08] here in our sort of rag data Pipeline
[03:11] and obviously we want to use the same
[03:12] embeddings model so that they fit in the
[03:14] same near spaces so this question got
[03:17] embedded and its Dimensions got placed
[03:20] as a vector near the company chunk
[03:22] because they have similar text right
[03:24] similar meaning so then now that we have
[03:27] our query embedded as a vector the query
[03:29] is going to grab the nearest maybe four
[03:31] or six sort of vectors based on the way
[03:33] you configure it and it's going to grab
[03:35] the near chunks and then pull them back
[03:36] so now down here what we're looking at
[03:37] is we get the vector back as a chunk and
[03:40] we can read the content of it and then
[03:42] we get the query back as well and then
[03:44] these two things are sort of augmented
[03:45] together with an llm in order to create
[03:47] that response which is the output and
[03:49] that's sort of the end of the process so
[03:51] with traditional rag it's kind of a
[03:52] one-hot query grab stuff back here's the
[03:55] response now when it comes to a gentic
[03:57] rag there's just a little more reasoning
[03:59] involved and it's maybe not always just
[04:01] a one shot process it still starts off
[04:03] with a trigger which is US asking a
[04:04] query to the agent but now instead of
[04:06] the agent directly turning that into an
[04:09] a dimension and a vector and then
[04:10] pulling that back it's going to look at
[04:13] this the context of what it has and it's
[04:15] going to be a little more aware of the
[04:17] decisions that it could make in order to
[04:18] get the most effective query out there
[04:21] so it can look at the different
[04:22] databases that it has access to it can
[04:24] look at the different schemas so maybe
[04:25] we have a ton of um not only text data
[04:28] but we have relational tabular data
[04:30] somewhere in a different database and in
[04:32] that case we want to do a SQL query and
[04:33] we have to look at the schemas it can
[04:35] also look at all the file content that
[04:37] we have in order to maybe understand um
[04:40] you know we have 10 documents in here
[04:42] how do we know which query Associates to
[04:43] which document so it can read file
[04:45] contents it can look at the actual
[04:46] documents and understand you know like
[04:48] the file IDs or the names of the
[04:49] documents coming through and then once
[04:51] it has that information it's able to say
[04:53] okay I'm going to send this off to the
[04:54] vector database to get embedded and then
[04:56] put in there to grab the information
[04:58] back or it's going to understand okay
[04:59] based on the question I'm going to be
[05:01] looking in like our sales data
[05:02] spreadsheet which is not going to be
[05:04] vectorized we want to look at a SQL
[05:06] query so then I'm going to make a SQL
[05:07] query in order to hit the right database
[05:09] there so it's just going to be a lot
[05:11] more efficient it's going to be a lot
[05:13] more relevant and we need to understand
[05:16] why so let's look at these other
[05:17] visualizations why does this actually
[05:19] matter at this point it may make sense
[05:21] oh yeah like having a reasoning aspect
[05:22] of an agent to before it sends out the
[05:24] query it sounds great but what really
[05:26] does that even mean so let's let's go
[05:28] back to the vector database example the
[05:31] agent is going to be taking our query
[05:32] and it's going to make one and then it's
[05:34] going to be looking in the vector
[05:35] database for chunks and it's just
[05:37] looking at chunks so this is going to
[05:40] miss out on the context of the entire
[05:43] document so maybe you know we're looking
[05:45] within a PDF that's 20 pages and we're
[05:47] just looking for specific chunks within
[05:48] that PDF but if we wanted to be able to
[05:50] read the entire PDF in order to reason
[05:52] which chunks actually make the most
[05:53] sense here we wouldn't be able to so
[05:56] it's it would just be looking for chunks
[05:57] right and that's why when Gemini dropped
[05:59] its a million context window that really
[06:02] changed the game because now a model can
[06:04] read the entire document before pulling
[06:06] back the answer so here's a little more
[06:08] practical example of what this means
[06:10] let's say we're asking the agent to
[06:11] summarize the meeting on March 5th it's
[06:13] going to turn that into a query which is
[06:15] going to be something like March 5th
[06:16] meeting summary and if we're looking at
[06:18] a 20page PDF of March 5th's meeting
[06:21] we're not going to be able to get all of
[06:22] those chunks back in order to summarize
[06:24] the meeting it would just be pulling
[06:25] back five random chunks and then
[06:27] summarizing just those chunks so
[06:30] that is why we need the aspect of
[06:31] agentic rag and now also let's talk
[06:33] about it in the sense of tabular data
[06:35] real quick let's say we vectorized this
[06:37] spreadsheet which is actually the real
[06:38] example we're going to look at in a sec
[06:40] we have like weeks total sales total
[06:42] units order value unique customers
[06:44] repeat customers we have all this
[06:45] information for each week right and so
[06:47] let's say we asked the agent what week
[06:50] did we have the highest sales it would
[06:52] turn that into a query like highest
[06:54] sales it would then look at the chunks
[06:56] and it wouldn't really be able to grab
[06:57] the ones that are highest sales um and
[07:00] even if it did it would basically just
[07:01] be grabbing a chunk of rows and then it
[07:03] would be looking okay within this chunk
[07:05] which one's the highest so maybe it
[07:06] would say okay here's in the green
[07:08] 15,000 um total sales that's the highest
[07:11] out of this chunk and I'm going to say
[07:13] that week six is the highest total sales
[07:15] although if we really look at the data
[07:17] we can see that you know week 19 is
[07:19] higher week 14 is higher week 24 is
[07:21] higher because the agent wasn't able to
[07:23] make an effective query to go through
[07:25] all of the total sales or look at the
[07:27] whole context of what's going on before
[07:29] it answers answer a very similar example
[07:31] down here would be what is our average
[07:32] order value it would basically just
[07:34] query something like average or like
[07:36] order value something like that right
[07:38] and once again it would just grab a
[07:40] chunk and then it would say okay out of
[07:41] this chunk I can try to do the math here
[07:43] and llms are not very good at math but I
[07:46] can try to do the math here and average
[07:47] these order value data points and it
[07:51] would give you back an answer and you
[07:52] may think it's right but it's not
[07:53] because it would not be looking at all
[07:55] 30 rows of your order values and you
[07:58] know a lot of times you're going to have
[07:59] more than just 30 rows so the more and
[08:01] more data you get in there the more
[08:02] essential it's going to be to be able to
[08:04] accurately and efficiently be able to
[08:06] like SQL query through this stuff rather
[08:08] than relying on your vectorization of
[08:10] your agent to be able to do stuff like
[08:12] average order value you know numerical
[08:14] data numerical analysis stuff like that
[08:18] by the way if some of these concepts are
[08:19] kind of daunting to you and you're
[08:20] looking for a more Hands-On approach to
[08:21] learning Ed end and Vector databases and
[08:23] stuff like that I would definitely
[08:24] encourage you to check out my paid
[08:25] Community the link for that's down in
[08:26] the description we've got a classroom
[08:28] section with stuff like building a
[08:29] agents intro to a automation deep Dives
[08:31] on Vector databases and rag API HTTP
[08:34] requests and then I'm doing step-by-step
[08:35] builds of a lot of the videos you see on
[08:37] YouTube which I think are the best way
[08:38] to learn so we've also got five live
[08:40] calls per week to make sure you're
[08:41] getting in there getting your questions
[08:42] answered and never getting stuck so i'
[08:44] love to see you guys in these calls but
[08:46] let's get back to the video all right so
[08:47] now we're actually in nadn and we're
[08:49] looking at Cole mean's recent template
[08:51] where basically the best agenta grag
[08:54] template that I've ever played around
[08:55] with he makes it super easy because he
[08:57] has these three nodes here where you can
[08:59] just run run them and it will create
[09:00] your database setups in superbase so
[09:02] we're using superbase right here we have
[09:04] a documents table which is our actual
[09:05] vectorization here are you know the
[09:07] content of our different documents we're
[09:09] looking at here's the metadata here are
[09:10] the embeddings we have the document row
[09:12] table so anytime we want to upload a you
[09:14] know a tabular form of data like CSV or
[09:17] Google Sheets it's going to put all the
[09:20] rows in here that the agent's able to
[09:21] query through so we have all 30 rows of
[09:23] our spreadsheet right here and then we
[09:25] have document metadata so we uploaded
[09:27] three files and we get all three files
[09:28] as each unique rows which the ID um of
[09:32] each one the title of each one and then
[09:34] which is really cool the sales data is
[09:36] tabular so it pulls in the schema and
[09:38] the agent will be able to look at the
[09:39] schema in order to make that SQL query
[09:41] these two are both just PDF so there's
[09:43] no schema but anyways you'll be able to
[09:44] run those three after you connect your
[09:46] credentials and you'll get the taable
[09:47] set up and then the rest of the workflow
[09:49] is going to work for you so this is like
[09:50] I said probably the coolest template
[09:52] I've ever seen on n in and just huge
[09:54] shout out to Cole here he doesn't need
[09:55] me to help him promote any of his
[09:57] content he's killing it but Cole this is
[09:59] awesome man so of course if you want to
[10:01] get this template to play around with
[10:02] it'll be available for download for free
[10:04] in my free school Community but I'll
[10:06] also leave the link in the description
[10:07] to Cole's video about it he also
[10:09] provides that template for free of
[10:10] course and um he has a video where he
[10:13] kind of deep dives into like what's
[10:14] going on within this Pipeline and also
[10:16] like how he built all this kind of stuff
[10:18] so definitely go check out that video
[10:20] one quick thing though in in this node
[10:21] where you're setting up the documents
[10:23] table which is the vector database if
[10:24] you've already created one before in
[10:26] your superbase environment you can get
[10:27] rid of this first line which enables the
[10:30] PG Vector extension extension um because
[10:33] you don't have to create it again if
[10:34] you've already created it so do that and
[10:36] then also if you want to change the name
[10:37] from documents you'll have to change
[10:39] this and then you want to change the
[10:40] other instances of the word documents
[10:42] within this code but anyways you'll run
[10:45] those you'll get set up and now let's
[10:46] chat with our data so the three docs
[10:48] that we have in here are we have our
[10:49] sales data which is right here as you
[10:51] can see we have 30 rows of sales data we
[10:54] have our green grass AI implementation
[10:56] proposal and we have our Mountaintop AI
[10:58] implementation proposal and they're all
[10:59] in here so the agent has to be able to
[11:01] figure out okay which of these three
[11:03] docs do I need to look in if it is the
[11:05] sales data I probably need to do a SQL
[11:07] query and it has the different tools
[11:09] like listing documents getting file
[11:11] contents query document rows and then of
[11:13] course the superbase pector store so
[11:15] let's try out some queries okay so the
[11:16] first one I'm saying is which week has
[11:18] the highest total sales we're going to
[11:20] see it um update its memory it's going
[11:21] to list the documents it's getting the
[11:23] schema and now it went to make a a SQL
[11:25] query it failed the first time it tried
[11:27] to hit it again and now it's getting the
[11:28] file contents to pull that back so what
[11:30] we got was the week with the highest
[11:32] total sales is week four with total
[11:34] sales amounting to
[11:35] 19423 if we go into the document we can
[11:37] see that week four that is the correct
[11:39] amount of sales and if we look through
[11:42] closer and I obviously could do a Google
[11:44] Sheets function to verify but that is
[11:46] the highest week of sales so what
[11:48] happened here was let's click into the
[11:49] logs basically it tried to it listed
[11:52] documents and it understood okay I need
[11:54] to go to the sales data which is right
[11:55] here sales data and here's the schema it
[11:58] tried to make a query so we got a query
[12:00] it didn't come through right the first
[12:02] time you know something was wrong with
[12:03] the numeric data hey guys while editing
[12:05] I noticed that this errored because
[12:07] there was no value in week 19 for the
[12:09] total sales so that's why the SQL query
[12:11] failed twice but um it was good to show
[12:13] off the functionality of it fetching
[12:15] file contents if it did error so it was
[12:17] always a good fail save but um yeah
[12:19] that's why it AED if anyone was curious
[12:20] it tried to make a query again and it
[12:22] aired again so then it's fail safe was
[12:24] okay I'm just going to grab all file
[12:25] contents of this ID and it knew to get
[12:27] this ID because earlier it listed
[12:29] documents and it saw the ID of the sales
[12:31] table and from there it could see this
[12:34] data could see all of it and then it was
[12:35] able to make the response which was week
[12:37] four has the highest amount of sales
[12:39] okay but just to show you that the SQL
[12:40] quering does work let's try another one
[12:42] what is our average unique customers per
[12:43] week so it's going to obviously hit the
[12:45] memory it's listing documents to get
[12:47] that schema now it's going to be trying
[12:48] to make a query there we go we got green
[12:50] and we got the average unique customers
[12:52] per week is approximately 171 so if we
[12:54] come in here and real quick I'm just
[12:56] going to do an average of um what did I
[12:58] say meet customers so we'll grab this
[13:01] and we'll see oops the answer right
[13:03] there it made a new column but the
[13:04] answer is
[13:05] 17107 which is exactly what we got here
[13:08] and we'll click into this query and we
[13:10] can see what it did is that it was able
[13:12] to generate this query so Cole obviously
[13:13] wrote all this stuff so great work there
[13:15] again but what it's doing is it's
[13:17] selecting the average out of all the
[13:19] unique customers from the correct
[13:21] document um and then it's doing that
[13:23] with a SQL query math rather than the
[13:25] llm relying on or rather than us relying
[13:28] on llm to do math so so this is why we
[13:29] got the exact answer here which is what
[13:31] we saw in our Google Sheets and then one
[13:32] more query we're going to do is how many
[13:34] total units sold from weeks 4 through 10
[13:36] we'll send that off and it's going to
[13:38] once again probably list the documents
[13:39] to get the schema and now it's going to
[13:41] create that SQL query we already got
[13:42] that back and it said the total units
[13:44] sold from week 4 to 12 is
[13:46] 2,139 real quick let's just do a quick
[13:49] sum of the total units sold from what
[13:51] did I say week four week 10 and we get
[13:54] 2139 which is exactly what our agent
[13:57] said it queried it by basically saying
[13:59] um it want I want to sum the tonal units
[14:01] sold from this ID um and the weak has to
[14:04] be between 4 and 10 so absolutely
[14:07] amazing okay so now we want to look at
[14:09] let's see if we can hit the vector
[14:11] database to pull back some information
[14:12] about green grass AI implementation
[14:14] proposal not Mountaintop so we'll say
[14:17] like what is going on within the
[14:18] automated email and Outreach within our
[14:20] green grass project we'll see what tools
[14:22] it uses so first of all just went
[14:23] straight to the superbase vector
[14:24] database and we'll see if we get back
[14:26] something accurate by the way using 40
[14:30] um for mini okay so for mini this is and
[14:33] it's already still working really well
[14:35] anyways let's see what we got here the
[14:37] email Outreach within Greengrass project
[14:38] is aimed at automating and enhancing the
[14:40] sales Outreach and Lead qualification
[14:42] through AI powered automation so we have
[14:44] objectives a stream line engagement it
[14:46] gave us the full scope of work and it
[14:47] gave us expected outcomes project
[14:49] timeline as well so it gave us a pretty
[14:51] detailed um piece of information back
[14:53] come in here and we can see that if we
[14:54] were to cross check all of this it would
[14:56] be accurate and now what I want to do
[14:57] real quick is just hop into the agent
[14:59] click on its logs and we'll see exactly
[15:00] what it did as far as the query it sent
[15:02] off to superbase so what it did is it
[15:05] queried email Outreach green grass
[15:06] project so it was able to pull back this
[15:08] Chunk from the green grass it was able
[15:10] to um pull back the expected outcomes
[15:13] and pull back just basically this
[15:14] information about our green grass
[15:16] project okay we're going to try
[15:18] something a little trickier so I'm going
[15:19] to say which project is the cost
[15:20] estimate 50,000 so in green grass it's
[15:23] 25 mountain top it's 50 so let's send
[15:25] this off and just see how the agent
[15:27] thinks about it and we'll see if it hits
[15:28] any the different tools um it went
[15:30] straight to the super base and it looks
[15:31] like that was already its answer and it
[15:34] said the project with a cost estimate of
[15:35] 50k is Mountaintop AI implementation
[15:37] proposal we'll click into the agent go
[15:39] to its logs and see what it sent off and
[15:41] it said cost estimate $50,000 project
[15:44] and it was able to pull back chunks
[15:46] based on that query and then it was able
[15:48] to determine that that was the um
[15:51] Mountaintop project okay going to try
[15:53] one more thing here and I'm going to say
[15:54] give me a concise summary of all of our
[15:56] projects and that's not a question mark
[15:57] That's a command so I'm sending that off
[15:59] and I'm interested to see this here
[16:01] because as we know with chunks it would
[16:03] have to pull back a ton of them right so
[16:06] it's thinking about it as you can see
[16:07] this one thought about it longer okay so
[16:09] it actually what it did was it used its
[16:10] memory okay so I'm going to clear the
[16:12] memory in postgress as well we cleared
[16:15] the chat history within our NAD end so
[16:16] now it has no memory to work off of and
[16:18] I'm going to say give me a concise
[16:19] summary of all of our projects so we'll
[16:21] see what it does here it's hitting the
[16:22] superb based Vector store I think that's
[16:24] the only thing it's going to do here so
[16:25] we will see how accurate this is but
[16:28] okay so so we have green grass it gave
[16:30] us the project name scope of work text
[16:32] stack um and then it gave us the exact
[16:34] same thing for Mountaintop except for it
[16:36] didn't give us a Tex stack so what's
[16:38] going on here is if we go to logs we go
[16:40] to superbase Vector store it said
[16:41] summary of all projects so this is one
[16:43] of the limitations of course of exactly
[16:46] what we were talking about earlier with
[16:47] chunking because it got back it looks
[16:49] like four chunks and it did four because
[16:51] in here we set the limit to four now if
[16:53] we were to set this limit to oh sorry if
[16:55] we were to set this limit to 10 now it's
[16:57] going to be pulling back 10 chunks and
[16:58] if we did this again we would see that
[17:00] we're probably getting more details
[17:02] about our projects because it just has
[17:03] more information to work with so what we
[17:05] wanted to be doing is probably using get
[17:07] file contents to get all of the
[17:09] information based on the ID so we'd want
[17:12] it to probably list documents and then
[17:13] get file contents to pull back those two
[17:15] IDs and get everything as you can see
[17:17] this is more detailed now because we
[17:18] increased the limit but as Cole
[17:20] mentioned in the video it can be hard to
[17:22] get the AI to do that because it's like
[17:24] it's technically not going to fail and
[17:26] and this is more of a fail safe so like
[17:28] as you saw when we tried to do the query
[17:29] and that didn't work so then it uses as
[17:31] a fail safe so what I'm going to do is
[17:32] just explicitly prompt it to um give me
[17:36] a summary of the
[17:40] projects you know by using git file
[17:45] contents tool so we'll see if that does
[17:47] anything um okay so it's listing
[17:50] documents now it's going to hit the get
[17:52] file contents and now we're going to
[17:53] have it it pulled back two file contents
[17:55] as you can see so it's getting all of
[17:57] the information about our two projects
[17:59] and now it's trying to construct that
[18:01] into a concise summary for us um so
[18:04] we're about to get that answer now we
[18:06] have the actual full contents of the
[18:07] project there and so if we click in here
[18:09] in the logs we'll see first it listed
[18:11] documents so it was able to say okay
[18:13] here's the ID for our project here's the
[18:15] ID for our second project and now I'm
[18:17] going to get file contents so as you can
[18:18] see it got everything because it it
[18:21] filtered by this ID and then it did it
[18:22] again for the second project filtering
[18:24] by this ID and now we have the actual
[18:26] full document so that's what we wanted
[18:28] to do um and it's hard to make the AI do
[18:31] that without like an actual error over
[18:32] here but as you can see that's the way
[18:34] it was able to like look through
[18:36] projects grab those IDs and then get
[18:37] everything back so that's going to be it
[18:39] for this one like I said super super
[18:41] cool template he even has a full rag
[18:42] pipeline down here that handles PDFs
[18:45] text or any tabular data and it will
[18:47] create those rows and it will aggregate
[18:48] it and still push it in um so super
[18:51] super cool template here huge shout out
[18:53] to Cole once again thanks for you know
[18:55] doing this for the whole ended End
[18:56] Community it's really cool he also made
[18:58] a local hosted one if you're interested
[19:00] in that so definitely check out his
[19:01] channel like I said the link will be
[19:03] down below but um thanks guys I really
[19:05] appreciate you making it to the end of
[19:06] this video if this was helpful if you
[19:08] learned something new then definitely
[19:10] hit that like button let me know what
[19:11] else you guys want to see it definitely
[19:12] helps me out and I will see you guys in
[19:14] the next one thanks