Video Title: Having an Actual Conversation with Data Using an ElevenLabs Voice Agent and n8n
Video ID: pJYm7MOyMH0
URL: https://www.youtube.com/watch?v=pJYm7MOyMH0
View Count: 51,683

[00:00] hey there I'm Eric what information are
[00:01] you looking for today hey Eric I missed
[00:04] the last meeting could you fill me in on
[00:05] the current challenges that we're facing
[00:06] with our AI chap out
[00:11] project okay um let me check the project
[00:13] database the main challenges right now
[00:15] are integration issues with third-party
[00:17] apis causing delays and the chatbot
[00:20] having trouble handling complex customer
[00:22] queries that need multiple steps of
[00:24] reasoning okay got it and what team
[00:26] members are working on this project and
[00:28] what do the Milestones look like here
[00:33] okay let me see the team members are
[00:35] Alice Bob and Charlie the current
[00:37] Milestones are basic chatbot framework
[00:39] implementation by January 15 integration
[00:42] with the website and app by February 5
[00:44] and internal testing and debugging by
[00:46] February 20 all right awesome and we
[00:48] were targeting for the product to be
[00:50] wrapped up by March
[00:54] right let me quickly check that for you
[00:57] yes the target launch date is March 1
[01:00] okay cool that's all I've got for you
[01:02] okay great is there anything else I can
[01:04] help you with
[01:05] today nope that's it thanks Eric you're
[01:08] welcome let me know if you have any
[01:09] other questions okay so there was a
[01:11] quick demo of the project manager
[01:13] conversational voice agent that we're
[01:14] going to be breaking down today as you
[01:16] can see we have the workflow on end and
[01:17] end and then we have the 11 Labs voice
[01:19] agent and it has access to a vector
[01:21] store that has all our information on
[01:23] that Google doc that you saw right here
[01:25] about our projects so let's get into
[01:27] this build okay so AI voice agents they
[01:29] they seem a little complicated but
[01:31] they're really not so I'm going to try
[01:31] to break it down um in a way that's all
[01:33] going to make sense and you're probably
[01:35] already 75% of the way there so what
[01:38] we're looking at here is just a rag AI
[01:40] agent within nadn you've probably built
[01:42] one of these before we have our chat
[01:43] model we have the vector database um and
[01:46] that's really it so today we're going to
[01:47] be breaking down three main things we
[01:49] have our Vector database we have the NN
[01:51] agent and then we have um the 11 Labs
[01:55] voice agent so we're going to start off
[01:57] here in Ed end we're going to break down
[01:59] um how we're talking to it through the
[02:00] web hooks how it responds um what's
[02:02] going on here and then we'll get into 11
[02:04] labs and look at how we actually prompt
[02:06] The Voice agent to extract the
[02:07] information it's looking for and then
[02:09] send that post request to us in NN so
[02:11] that we can hit this Vector store and
[02:13] respond back first things first getting
[02:15] our information into the vector database
[02:17] in Pine Cone so we have our Google doc
[02:19] right here as you can see it has three
[02:20] projects um we push that into pine cone
[02:23] using this workflow here where we
[02:24] download it from Google Drive we
[02:26] extracted the text and then we pushed it
[02:28] into pine cone in a namespace called
[02:30] projects so as you can see in Pine Cone
[02:32] we have a namespace called projects it
[02:33] created four vectors as you can see
[02:35] right here four items and then in our
[02:37] voice or sorry in our rag agent we need
[02:39] to make sure that we're sending this
[02:41] agent to that namespace again called
[02:43] projects so it's looking through for the
[02:45] right stuff so I know I went over that
[02:46] pretty quick but you can download this
[02:48] workflow as well as this workflow from
[02:50] my free school Community the link for
[02:51] that will be down in the description you
[02:53] will just come in here click on YouTube
[02:54] resources you'll click on the post
[02:56] associated with this video and then you
[02:58] have all the files right here to
[02:59] download you'll come in nadn and you can
[03:01] download them or sorry you can import
[03:02] them right here from file and then
[03:03] you'll have everything up and running um
[03:05] good to go then if you want to take your
[03:07] skills with NAD a little bit further get
[03:08] some more Hands-On help please check out
[03:10] the paid Community we've got um you know
[03:12] great Community they asking questions
[03:13] sharing bills that kind of stuff you get
[03:15] your questions answered a lot faster in
[03:16] here um as well as about five live calls
[03:19] per week a great classroom section
[03:21] that's constantly growing as the space
[03:23] evolves as we're learning more and yeah
[03:25] I would just love to see you guys in
[03:26] here you can check that out in the
[03:27] description anyways back to the agent so
[03:29] so um it's a super simple build as you
[03:31] can see within my AI agent here we set
[03:33] it up as a tools agent and I didn't even
[03:35] give it a system prompt because it only
[03:36] has one tool and it's pretty easy
[03:38] because the query comes in and then it
[03:39] has to search through here we Define
[03:41] that this is a project database it says
[03:42] it retrieves information about our
[03:44] projects so not much area for the AI
[03:46] agent to get confused here if you hooked
[03:48] up more tools of course you'd want to
[03:49] prompt it a little bit but um it's very
[03:52] simple rag agent right and if you've
[03:54] built one out in nadn before you've
[03:56] probably connected it through the nadn
[03:58] chat Trigger or you connected it to
[04:00] telegram or email or
[04:02] slack it's pretty much the same thing
[04:04] here except for now we're talking to it
[04:05] through voice using 11 Labs so you could
[04:08] even grab an AI agent that you already
[04:09] have built and all you have to do is
[04:11] switch out how are we talking to the
[04:12] agent and how is it responding back so
[04:14] it's much more simple than you may think
[04:16] in this case we're sending information
[04:17] to the agent using 11 labs and then the
[04:19] agent communicates back and sends it
[04:21] back to 11 Labs so that's why we're
[04:22] using web hooks here so we'll click into
[04:24] the web hook as you can see it's a
[04:25] trigger so it's actively listening for
[04:27] the agent to conversate with a human and
[04:29] then send over over that question so
[04:31] we've got um this is a post method
[04:33] method because like I said 11 Labs is
[04:34] sending information to us to NN we've
[04:37] got a URL here and right now it's a test
[04:39] URL when the workflow in NN is active
[04:42] you this will switch to a production URL
[04:43] so you'll have to switch out that URL in
[04:46] 11 Labs but um for now we're doing test
[04:48] and we'll have to listen manually for
[04:50] each event the path all this does is
[04:52] change the actual URL so you can play
[04:54] around with that if you just want to
[04:54] clean it up and then as far as
[04:56] authentication we don't need any but for
[04:58] the response make sure you use um
[05:01] respond to web hook node rather than
[05:02] immediately or any of these other
[05:04] options so it's like I said the same way
[05:07] that you would text it with telegram it
[05:09] would get your text it would search
[05:11] through the vector database it would
[05:12] think about how to respond it would
[05:14] create a response and then it would
[05:15] telegram you back it's the exact same
[05:17] process except for we're getting a query
[05:19] from 11 labs and then the agent is
[05:21] responding back to 11 Labs so that's how
[05:24] this is going to work okay so let's
[05:25] click into do an execution and actually
[05:27] see this happen so this is the first
[05:30] question that we just asked in the demo
[05:31] earlier in this video let's look at the
[05:33] web hook trigger um we've got all this
[05:35] stuff coming through but really all
[05:36] we're looking for is the body which is
[05:38] the parameter we sent over from 11 Labs
[05:40] called question the question here is
[05:42] what are the current challenges for the
[05:43] AI chapot project so this question gets
[05:47] sent over to the agent as you can see
[05:48] right here json. body. and we just drag
[05:51] that in from down here where we can see
[05:53] everything that came back from the web
[05:54] hook so now the agent uses this question
[05:57] to hit the tools it needs to to create
[05:59] this output over here which it
[06:01] eventually sends back to 11 Labs but
[06:02] let's click into the logs and take a
[06:04] look at what actually is going on so um
[06:08] what we see is that it's getting the
[06:09] question right here which is what are
[06:10] the current challenges it's going to
[06:11] send that to the vector database tool um
[06:14] and then we got a response but before we
[06:16] get the response the vector database
[06:18] tool has to go search through the vector
[06:19] database so here's the question here is
[06:22] what's in the vector database it has to
[06:24] search through the embeddings as you can
[06:25] see here with the um different
[06:26] parameters and then it's going to send
[06:28] this back to the opening ey chat model
[06:30] to look through and actually create a
[06:32] response based on the question that the
[06:34] human asked in the first place so now we
[06:36] got this output and finally it comes
[06:37] back to the agent where this is the
[06:40] final output that we got and then that
[06:42] gets sent right over to the web hook so
[06:44] hopefully that all makes sense yeah it's
[06:46] really not too complicated when you
[06:47] really break down and when you
[06:48] understand the fact that you could
[06:49] probably take this rag system that you
[06:51] already had built out this rag AI agent
[06:53] system and all you're doing is changing
[06:55] the input and changing the output and
[06:57] then you know exactly you're changing
[07:00] what's going on right here um what the
[07:02] agent's actually looking at as far as
[07:04] the input but that's really as simple as
[07:06] it needs to be okay so now let's look at
[07:09] what's actually going on within 11 Labs
[07:11] so I'm in 11 Labs we're at the
[07:13] conversational agents section um and
[07:16] this is the agent that we were just
[07:17] looking at Eric he was a project manager
[07:19] and I just it's Eric because that's
[07:21] that's the name of the voice in here as
[07:22] you can see is poverty there you go
[07:24] perfect um but there's just a couple
[07:26] things that we want to set up here so
[07:27] within the agent the first thing to to
[07:29] do is set up the first message if you
[07:31] leave it blank then when you click call
[07:33] you'll just start talking rather than
[07:34] the agent talking to you but we just
[07:36] said hey there I'm Eric what information
[07:37] you're looking for today then we set up
[07:39] the system prompt so this you know
[07:41] there's a lot of testing that goes where
[07:42] you set up a prompt you call it you talk
[07:45] to it you see what it's like and then
[07:47] you come back and change some things but
[07:49] essentially here's the prompts we have
[07:50] you are a project manager responsible
[07:52] for providing accurate and helpful
[07:53] information about current projects Your
[07:56] Role is to actively listen to the user's
[07:57] question understand their intent and use
[07:59] the nend tool which I'll show you guys
[08:01] how to set up the nend tool in 11 labs
[08:03] in a sec but you use the nend tool to
[08:06] query the project database after you
[08:08] receive the response from NN then you
[08:10] provide the user with a clear and
[08:11] concise answer based on that data and
[08:13] then I came in here at the end and said
[08:14] maintain a friendly tone use filler
[08:16] words like um and okay when you're
[08:18] actively listening and waiting don't
[08:19] repeat the question back to the user
[08:21] just give a concise answer so right here
[08:23] we're using the model
[08:24] llm um Gemini 1.5 flash it's the fastest
[08:27] as you can see you have other options to
[08:29] choose from though and then for
[08:31] temperature um I think default it's set
[08:33] at like you know 0.5 right here but I
[08:35] set it at 08 basically just the
[08:37] randomness and creativity of the
[08:38] responses that you're going to get from
[08:40] um whatever llm that you choose and I
[08:42] think that it's fun to have it a little
[08:43] higher especially with something like
[08:44] rag right now but um you know if you
[08:47] really needed like specific information
[08:48] on policies or you know stuff like that
[08:51] where it has to be um precise then you
[08:53] would probably want this to be lower
[08:55] anyways um token usage um you could hook
[08:59] up knowledge base but it would be a
[09:01] little bit more static so we want to use
[09:03] a vector database that it's going to be
[09:04] called through n at end because then we
[09:06] can update the vector database with some
[09:08] sort of automated pipeline rather than
[09:09] just having like um certain files in
[09:11] here right but anyways this is where the
[09:14] magic really happens the tool section so
[09:16] as you can see we only have one tool and
[09:17] it's called nadn so what we did in here
[09:20] was we named it nadn because just easier
[09:23] for prompting is we understand that it's
[09:25] going to be sending information to NN
[09:26] and then waiting for a response from NN
[09:28] the description here is use this tool to
[09:30] access the project database and then
[09:32] this is where we set up our web hook
[09:33] sort of requests so we're using a post
[09:35] because we want to send information to
[09:37] Ed end and then we have the URL which is
[09:40] just the one that we grabbed from this
[09:41] web hook right here click to copy and
[09:43] then we pasted that right in there and
[09:46] then you can leave all of this stuff as
[09:47] it is besides the body parameters we
[09:49] actually do need to set up so this is
[09:52] because like I said we're sending
[09:53] information over which is going to be
[09:55] the question um so here we need to add a
[09:58] description which is um this information
[10:01] is going to be passed to the llm and
[10:02] it's going to describe how to extract
[10:04] data from the conversation that you're
[10:05] having with this voice agent so right
[10:08] now all we had to say was ask the user
[10:09] what question or questions they have but
[10:11] if you needed to extract more you know
[10:13] more detailed information or more
[10:14] information like if you're appointment
[10:16] setting or you're gathering information
[10:18] like you know what's your name your
[10:19] email your um phone number all this kind
[10:22] of stuff then you'd have to set up
[10:23] different parameters for each thing so
[10:25] you'd have name you'd have phone number
[10:27] you'd have you know how many guests
[10:29] um what time do you want to come all
[10:31] that kind of stuff if you know based on
[10:32] the use case but right here all we
[10:34] needed was the question and the
[10:35] description is question from the user so
[10:37] that's why um in
[10:40] NN when we're actually getting the
[10:42] response back from the web hook it came
[10:44] through in the body parameter called
[10:47] question so right here um we have
[10:49] question like I said if you had a
[10:50] different use case you would here you'd
[10:52] have name email date whatever it is but
[10:55] this is question because we called this
[10:57] question right here so that's all we had
[10:58] to do um we save that and now we have
[11:01] pretty much this stuff set up and that
[11:03] is why it knows here to call the tool
[11:05] nadn um using that web hook okay so now
[11:08] that we got everything set up within 11
[11:10] Labs we'll go ahead and test out the AI
[11:12] agent and just a reminder everything in
[11:14] NN right now is still in a test
[11:16] environment it's not an active workflow
[11:18] so we're using the test URL in our web
[11:20] hook we would switch this to production
[11:21] and then it would be actively listening
[11:23] all the time but for now we have to
[11:25] manually hit test workflow so that it's
[11:26] listening for 11 Labs post request so
[11:29] what I'm going to do is talk to the
[11:30] agent we'll ask a question it's not
[11:32] going to be able to access this Vector
[11:33] database because the web hook isn't
[11:34] active and then we'll ask it to try
[11:36] again and it should be able to get the
[11:38] information the second time so let's do
[11:40] that hey there I'm Eric what information
[11:42] are you looking for today hey Eric could
[11:44] you give me an update on our marketing
[11:46] dashboard
[11:49] project okay um let me check the
[11:51] database it looks like the project is
[11:53] not in our database can you double check
[11:56] the project name
[11:59] yeah no I'm pretty sure it's called
[12:00] marketing dashboard can you try
[12:06] again okay let me try again the
[12:08] marketing dashboard project is currently
[12:10] on
[12:14] track okay cool thanks for the
[12:16] update you're welcome is there anything
[12:19] else I can help you with today no that's
[12:21] it thanks
[12:22] Eric no problem have a great day okay so
[12:25] that's pretty much going to be it for
[12:25] this one I just wanted to come in here
[12:27] and make a quick one about how you
[12:28] connect 11 to Ed end super easily a lot
[12:31] more simple than you may think at the
[12:33] end of the day all we're doing is
[12:34] changing the input and the output so if
[12:36] you had something like a personal
[12:37] assistant agent that had the tools
[12:38] connected to it and a pretty robust
[12:40] prompt um as long as the agent's getting
[12:43] a query from something that it can take
[12:45] this query understand what it needs to
[12:47] do how to take action with its different
[12:48] tools and then respond back um you could
[12:50] pretty much integrate this sort of voice
[12:53] agent into any other nadn agent
[12:55] workflows that you already have built
[12:56] out just a little bit of prompting will
[12:58] have to go into the 11 lab side of
[13:00] things um like we talked about having to
[13:03] set up when to use different tools or
[13:05] when to send information to nadn um what
[13:07] parameters you want to send over within
[13:08] your tools if you need to get more
[13:09] information than just like a simple
[13:11] query or a simple question but um from
[13:14] there not too difficult so I hope that
[13:16] this one helps you guys um voice agents
[13:18] are going to be a pretty cool space I
[13:19] mean they already are but just heading
[13:21] into this new year um lots lots more use
[13:23] cases as this technology gets smarter
[13:25] and faster every day as always if this
[13:27] one helped please leave a like um
[13:29] comment what other use cases you want to
[13:30] see with some voice agents and I really
[13:32] appreciate you guys making it all the
[13:33] way to the end I will see you guys in
[13:35] the next one thanks