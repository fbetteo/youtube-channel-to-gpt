Video Title: Turn Your AI Agent Into a Voice Assistant in Minutes (n8n & ElevenLabs)
Video ID: qJRFu88HUio
URL: https://www.youtube.com/watch?v=qJRFu88HUio
View Count: 47,116

[00:00] Today I'm going to be talking about the
[00:01] easiest way that we can connect voice to
[00:03] our Naden workflows or agents for a
[00:05] better experience for the user. There
[00:07] are two ways that we can do this. The
[00:08] first one is using 11 Labs to turn text
[00:10] into speech and send that over as an
[00:12] audio file. And then the second one is
[00:14] where we use an 11 Labs voice agent to
[00:16] actually have a real-time conversation.
[00:18] It's going to be super easy and I'm
[00:19] going to walk through all of it live in
[00:20] front of you guys. So let's get started.
[00:22] Okay, the first scenario that we're
[00:24] going to walk through is one where we
[00:25] can send an AI agent a voice file and
[00:27] then it will process information and
[00:29] then send us back another voice file.
[00:30] So, it's not going to be a conversation,
[00:32] but it is going to deal with audio and
[00:34] audio. So, the way I'm going to do this
[00:36] today is going to be through Telegram.
[00:37] So, the first thing I'm going to do is
[00:38] add a Telegram node, which is going to
[00:41] be our trigger, which is going to be on
[00:43] message received. And so, what I'm going
[00:44] to do real quick is execute this step.
[00:46] So, it's going to be listening in our
[00:48] Telegram channel. I'm going to open up
[00:49] Telegram and I'm going to send off a
[00:50] voice message. Testing, testing. Can you
[00:52] hear me? So, we'll shoot that off. It
[00:54] should capture it right there. What we
[00:56] see on this output of the Telegram
[00:57] trigger is that we got this voice file
[00:59] right here. And we can tell it's a voice
[01:01] file because right here it says
[01:02] audio/ogg.
[01:05] So, now what we need to do is actually
[01:06] download this voice file and transcribe
[01:08] it so that we can send it to an AI
[01:09] agent. So, what I'm going to do is add
[01:11] another step right here. That's going to
[01:12] be a telegram node and we're going to
[01:15] download a file. Okay. So, it's actually
[01:17] get a file. It's right here. We're going
[01:18] to click on that. And what we're going
[01:19] to do is basically it's looking for a
[01:21] file ID to download. So all I have to do
[01:23] is scroll down on this lefth hand side,
[01:25] drag in this file ID right here. And if
[01:27] I hit execute step, it should basically
[01:29] pull over the voice file that we just
[01:31] dropped into it. And here's that voice
[01:33] file. Let me just play it for you guys
[01:34] real quick. Testing, testing. Can you
[01:37] hear me? Okay, so now we have that file.
[01:39] Now the next step is we need to
[01:40] transcribe it. Now in the past, what
[01:42] I've showed you guys with something like
[01:43] this personal assistant is we used
[01:45] OpenAI's transcribe recording node to
[01:47] transcribe it. And also what you're
[01:49] seeing here is the method where the
[01:50] personal assistant can get either text
[01:52] input or voice input. But in today's
[01:54] tutorial, we're just going to deal with
[01:55] voice. But the other way that you could
[01:57] do this is with 11 Labs to transcribe
[01:59] that recording. So I'm going to click on
[02:01] the plus. I'm going to type in 11 Labs.
[02:03] And this is actually an NAN verified
[02:05] community labs node. So if you don't see
[02:08] this option, you will just have to make
[02:10] sure your NADN version is updated to the
[02:12] release of verified community nodes. And
[02:15] then when you get this, you'll have to
[02:16] install it. And now you can see we have
[02:18] different actions and there's one down
[02:19] here that says transcribe audio or
[02:21] video. So I'm going to click on this
[02:23] one. It's going to ask us for an 11 Labs
[02:25] API key. So I'm just going to go ahead
[02:26] and set up a new one right here in front
[02:28] of you guys. So when I click on this
[02:30] button and go to create a new
[02:31] credential. It asks us for an 11Labs API
[02:33] key. So you're going to go over to 11
[02:35] Labs. The link for that will be down in
[02:37] the description. And once you sign up
[02:38] for an account, you can just get on like
[02:40] the $5 a month plan or you can just
[02:42] start for free. But I'm on the five
[02:43] bucks a month plan and it is not too bad
[02:45] at all. I hardly ever meet the credit
[02:47] limit. Anyways, in your profile down
[02:50] here, you're going to go to API keys
[02:53] right there. And then all you have to do
[02:54] is click create API key. And what it's
[02:56] doing now is asking for different
[02:57] permissions of this key. So what I'm
[02:59] going to do is make sure text to speech
[03:01] has access. Speech to speech has access.
[03:03] And just to be safe and give it access
[03:05] to everything, I could just turn this
[03:06] off so it has no restrictions. So I'm
[03:08] going to go ahead and create this new
[03:09] key. And then I'm going to copy this
[03:11] value right here. And once I close this,
[03:13] I can't get it again. So save that
[03:15] somewhere. And now that I've copied that
[03:16] key, I can go back into my workflow and
[03:18] just paste it in right here. We'll hit
[03:20] save and we should be all set.
[03:22] Connection tested successfully and we
[03:23] can now access 11 Labs through NAN. So
[03:26] what this is telling us is that it's
[03:27] going to turn speech into text and it's
[03:29] looking for a binary file in the field
[03:32] called data, which we can see is right
[03:33] over here. So these two things are
[03:35] linked up. I should be able to just hit
[03:37] execute step. And what it's going to do
[03:39] is turn that into text. So right here
[03:42] you can see exactly what I said which
[03:43] was testing testing. Can you hear me? So
[03:46] we have our speech turned into text
[03:47] thanks to 11 Labs. And now we need to
[03:49] hook up our AI agent. So I'm going to
[03:51] click on the plus. I'm going to type in
[03:53] AI agent. We'll grab this guy right
[03:54] here. First thing we need to do is set
[03:56] up the user message because by default
[03:59] the AI agent is set to look inside of
[04:01] the connected chat trigger node which
[04:03] does not exist on our workflow. We want
[04:05] it to instead look at the output of this
[04:07] node for the transcription. So all I
[04:10] have to do is click into the agent,
[04:11] change the user message to defined
[04:13] below, and then really simply I just
[04:15] have to drag the text field right here
[04:17] into this box. So it's now looking at
[04:20] this variable which represents whatever
[04:22] was transcribed. We could then go ahead
[04:24] and system prompt our AI agent. So I'm
[04:26] just going to say your helpful assistant
[04:28] who is extremely funny. Okay, so we're
[04:31] set up there. And now we have to connect
[04:33] a chat model. So I'm going to go ahead
[04:35] and connect an open router chat model.
[04:36] you would get this API key the exact
[04:38] same way you just got one from 11 Labs
[04:40] except for you'd go to open router.ai
[04:43] rather than 11 Labs. So once you're
[04:45] connected to your brain, we can go ahead
[04:47] and run this agent. It's basically
[04:48] looking at the message testing testing.
[04:50] Can you hear me? And then it's going to
[04:52] respond with something like loud and
[04:53] clear, I hear you like a bat in a cave
[04:55] with super sensitive sonar or like a
[04:57] mosquito with a PhD and eavesdropping.
[04:59] What's next? Very funny, assistant.
[05:02] Great work. And now all that's left is
[05:04] we have to turn that text into speech
[05:06] and then send it back to us in our
[05:08] telegram over here. So what I'm going to
[05:10] do is add another node and once again
[05:12] we're going to go to 11 labs. We are
[05:14] going to do convert text to speech. And
[05:16] now what we have to do is give it the
[05:18] text to turn into speech and we also
[05:20] have to give it the voice to use. So
[05:23] what we can do is just choose a voice
[05:25] from a list where we can see we have one
[05:27] of my voices, Nate Herk. We have Jarvis,
[05:29] we have Archer, we have all these
[05:30] different voices to choose from. And if
[05:32] you want to actually be able to go over
[05:34] to 11 Labs and test them out or you
[05:36] don't see one on this list that you
[05:37] want, let me just show you what you can
[05:39] do. So you'll go back over to 11 Labs.
[05:41] On this lefth hand side, you'll go to
[05:42] voices. And here you can see we have all
[05:44] of these different ones to choose from.
[05:46] And what you can do is kind of hear a
[05:48] preview of each one. So let's say I want
[05:50] to hear a preview of Young Jamal.
[05:51] What's good, bro? This is the only young
[05:53] black accent. So you can use it however
[05:56] you want. Cuz
[05:57] Or maybe we want to test out Jerry. Down
[05:59] in Dixie Land lived a young buck about
[06:01] knee high to a grasshopper.
[06:03] So if you're not seeing these in the
[06:05] list option, all you'd have to do is
[06:07] choose a voice that you like. Open up
[06:08] right here and click on copy voice ID.
[06:11] Once I've copied that, I would go back
[06:13] into the workflow and instead of
[06:14] choosing from a list, I would just
[06:15] choose by ID. Paste in the ID right
[06:17] there. And then we should be set up with
[06:19] that voice. And then all we have to do
[06:21] is drag the output of the AI agent into
[06:23] the text field. And then when we run
[06:25] this step, it should be turning that
[06:27] into an audio file. So if I download
[06:29] this file and we give it a listen real
[06:31] quick.
[06:31] Loud and clear. I hear you like a bat in
[06:34] a cave with super sensitive sonar or
[06:36] like a mosquito with a PhD and
[06:38] eavesdropping. What's next?
[06:41] There you go. So we have our voice file
[06:42] and now all we have to do is just send
[06:44] it back to our Telegram chat. So I'm
[06:47] going to click on the plus after the
[06:49] voice and I'm going to type in Telegram.
[06:52] What we're going to do is not send a
[06:53] message. We're going to send a file
[06:56] because it's going to be working with a
[06:57] file. So send an audio file. And so now
[07:00] there's three things to do really. The
[07:02] first one is where are we sending this
[07:03] to? So it needs a chat ID. So I'm going
[07:06] to click on schema and I'm going to go
[07:07] all the way back to our Telegram trigger
[07:09] because this contains metadata like the
[07:11] chat ID. So I would take this chat ID
[07:13] right here and drag it into that slot.
[07:16] And now what's next is we need to tell
[07:17] it what to send over as audio. So you
[07:20] can see that we're working with our
[07:21] binary data field right here. So I have
[07:24] to tell Telegram we're going to be
[07:25] sending over binary. It's automatically
[07:27] going to look for a field called data
[07:28] which is right here. And now we should
[07:30] be good to go. And so now I think we're
[07:32] all set. I'm going to hit execute step.
[07:33] It's going to say success message has
[07:35] been sent. And now if I pull up my
[07:37] telegram we have an MP3 file that I can
[07:39] go ahead and play.
[07:40] Loud and clear. I hear you like a bat in
[07:43] a cave with
[07:44] cool. So that is basically how this
[07:45] thing works. Now keep in mind because
[07:47] this workflow is not active. If we
[07:49] wanted this to actually work, we'd have
[07:51] to turn this on as an active workflow.
[07:53] And now that it's active, let me try out
[07:55] a full thing real quick. Hello. How is
[07:57] your day going so far? We shoot that
[07:59] off. The workflow right now should have
[08:02] captured that, downloading it. The AI
[08:04] agent should be working right now to
[08:05] create a response. 11 Labs will turn
[08:08] that response into speech. And then any
[08:10] second now, we should get an audio file
[08:12] back. Oh, there it is. Let me hit play.
[08:15] Hey there. My day is going great. I've
[08:18] already answered a million questions and
[08:19] haven't broken a sweat. How about you?
[08:22] Been causing any digital chaos or just
[08:24] chilling like a chatbot villain?
[08:26] There we go. So, that is our funny sort
[08:28] of cowboy agent. Okay, so that was the
[08:31] first method. Now, what we're going to
[08:33] do is go down here and we are going to
[08:35] do a second one where we actually have a
[08:37] full conversational voice agent with 11
[08:40] Labs. So, we're going to head back over
[08:41] to 11 Labs real quick. And what we're
[08:43] going to do is on this left hand side,
[08:45] we are going to go to agents. So up on
[08:48] the top left, you're going to click on
[08:49] these arrows and you're going to choose
[08:50] conversational AI. And now we can set up
[08:52] a voice agent. So I'm going to click on
[08:55] agents and we're going to create a new
[08:57] one, which I'm just going to start from
[08:59] a blank agent. So I'm just going to call
[09:01] it test agent. We'll go ahead and
[09:02] create. And then we're going to have to
[09:03] set up certain things like a system
[09:05] prompt. And the most important thing
[09:06] we're going to set up is the tool
[09:08] calling. So right here is where you
[09:09] could choose the language. You could
[09:10] also go in here and choose the voice.
[09:12] We're just going to leave it as default
[09:13] for now. And then we can set up
[09:15] something like a first message. This is
[09:18] the first thing the agent will say when
[09:19] we call it. If it's empty, the agent
[09:21] will wait for the user, us, to start the
[09:23] conversation. So I'll keep it right now
[09:25] with hello, how can I help you today?
[09:27] And now before we set up the system
[09:28] prompt, let's real quick set up the
[09:30] actual tool call to talk to Naden. So
[09:33] I'm just going to scroll down and we are
[09:35] going to look for tools. Here's where
[09:37] you could customize letting your agent
[09:38] end the call, which we will give it
[09:40] access to. We can have it transferred to
[09:42] a different agent, transferred to a
[09:43] number, all of this kind of stuff. What
[09:45] we're looking to do is add a custom
[09:47] tool, which will let us send data to
[09:49] NAND, and then Nad can send data back to
[09:51] our agent. So, I'm going to click on add
[09:53] tool. You can see that we have all of
[09:55] these NAN ones that we've used in the
[09:57] past, but obviously we're going to
[09:58] create a new one. So, I'm going to click
[09:59] on add web hook tool. I'm going to call
[10:01] the tool NIDN. The description is call
[10:03] this tool to search the web. In this use
[10:05] case, we're just going to have the agent
[10:06] send data to NIDAN. the Naden AI agent
[10:08] will look it up online and then send a
[10:10] response back. And then what we need to
[10:12] do next is set up the method. So this is
[10:14] going to be post because we're sending
[10:15] data to it. And now we have to go get
[10:17] our NAND web hook URL to send data to.
[10:20] So we'll go back into N. We're going to
[10:22] add a web hook.
[10:25] And right now we are basically just
[10:27] going to grab this URL right here. We
[10:29] also have to make sure that our method
[10:30] is changed to post since that's how we
[10:32] set it up in 11 Labs. And we want to
[10:34] make sure that this thing can receive
[10:35] data. So, now that I've copied that URL,
[10:38] I'll paste that right in there. And then
[10:39] I'm just going to make the response time
[10:41] out as much as possible because we don't
[10:42] know how long it may take to search the
[10:44] internet. Now, for these headers and
[10:47] path parameters and query parameters,
[10:48] we're not going to worry about that too
[10:49] much. We are going to add one body
[10:52] parameter, which is going to be the
[10:53] actual search request. So, for the
[10:55] description, I said you're going to
[10:56] extract the search query the user is
[10:58] looking to find more information on. The
[10:59] string we're going to be sending over is
[11:02] going to be a search query. We'll do
[11:05] that in camel case. This will be
[11:06] required. And then we can set this up as
[11:08] either the LLM to basically extract it
[11:11] from our conversation. You could do a
[11:12] dynamic variable or a constant variable.
[11:14] We're going to leave it here as an LLM
[11:16] prompt. And then the description of this
[11:18] body parameter is what the user wants to
[11:20] look up online. So I'm going to go ahead
[11:22] and add this as a tool. So you can see
[11:24] the agent has access to our end to end
[11:26] tool. So now that's why I wanted to set
[11:27] it up before we system prompt it because
[11:29] we need to tell the agent how to behave.
[11:31] So what I'm going to do is use this
[11:32] describe with AI function where I can
[11:34] basically tell this 11 labs box what we
[11:37] want the agent to do and then it will
[11:38] generate us a system prompt. Okay. So I
[11:41] said I want to create a helpful research
[11:42] agent that will help the user to
[11:43] research and find more information using
[11:45] the web. We'll hit generate with AI and
[11:47] it should populate a system prompt for
[11:50] us. So we have a personality. His name
[11:52] is Remy. We have an environment, a tone,
[11:54] a goal, and then the one thing we forgot
[11:56] to do was tell it which tool to use. So
[11:59] I'm just going to manually change this.
[12:00] What I'm going to do is I'm going to say
[12:02] the tool is called nadn and we're going
[12:04] to use this tool to search the web and
[12:09] do research. And then I also said this
[12:11] tool will do research and send back a
[12:13] response. So you must wait for that
[12:14] response. What we're going to do is
[12:16] obviously have to test out this agent to
[12:17] see if it works. So I'm going to make
[12:19] sure I save this at the bottom of this
[12:21] workflow. And then what I'm going to do
[12:23] is click test AI agent. So when you
[12:25] click on test AI agent, it's going to
[12:26] open up a little test box like this. And
[12:29] before we actually call it, we want to
[12:30] make sure that our web hook in NAN is
[12:32] listening to us. So now it's listening.
[12:34] We'll go back into this test field and
[12:36] talk to the agent.
[12:38] Hello, how can I help you today?
[12:40] Hello, I'm looking to do some research
[12:42] on Nvidia.
[12:44] Okay, I can help with that. Is there
[12:46] anything specific you would like to know
[12:48] about Nvidia? For example, are you
[12:50] interested in their stock price, their
[12:52] products, or something else?
[12:54] Yeah, let's just look at their Q4 2025
[12:57] forecast.
[13:00] Okay, I will look for Nvidia's Q425
[13:03] forecast. Just to confirm, you're
[13:04] looking for their financial forecast for
[13:06] the fourth quarter of the year 2025.
[13:09] Correct.
[13:10] Correct.
[13:13] Okay. I've started a search for Nvidia's
[13:16] Q4 2020.
[13:17] Okay. So, I'm going to end that call.
[13:19] What I didn't like was how long it took
[13:21] to send data to the web hook. You can
[13:22] see that we captured it, but we maybe
[13:24] want it to be a little more straight to
[13:25] the point. So, we'll go ahead and change
[13:26] that in the system prompts later. But
[13:28] what we can see is that we did get the
[13:31] 11 Labs agent to send data over to
[13:33] Naden. So, I'm just going to go ahead
[13:34] and pin this so we can save it for now
[13:36] and we don't have to keep talking to
[13:37] Remy. But at the bottom, you can see it
[13:40] filled out our search query as Nvidia Q4
[13:42] 2025 forecast, which is exactly what we
[13:45] wanted. So, now we just need to set up
[13:46] an AI agent that will receive this
[13:48] message and then use a tool to do
[13:50] research on it. But actually, I don't
[13:52] even want to use an agent because that
[13:54] would be double processing because
[13:55] what's going on in 11 Labs is we're
[13:57] using an AI agent to conversate and
[14:00] think about tool calling. It ends up
[14:02] deciding to call this tool. And then
[14:04] what happens is if we were to create
[14:06] another agent in here with another
[14:08] aspect of reasoning, it would just be
[14:09] duplicating that for no reason. So maybe
[14:12] what would be smarter is in 11 Labs we
[14:14] set up this workflow web hook as a tool
[14:17] called research and then we can send
[14:19] data to this tool just to be researched
[14:21] and that's what we're going to do here.
[14:23] So rather than passing this data into an
[14:26] agent I'm just going to pass it into a
[14:27] perplexity node that's going to do
[14:29] research. So I'm going to click on this
[14:30] button. I'm going to type in perplexity.
[14:32] We're going to grab this right here and
[14:33] then we're going to message a model. I
[14:35] already have Proplexity set up, but if
[14:37] you don't, same way you set up Open
[14:38] Router and 11 Labs, you just need to go
[14:40] get an API key at perplexity.ai.
[14:43] And then I'm just going to choose Sonar
[14:45] for the actual text to do research on.
[14:47] We are going to drag in the search query
[14:48] that our 11 Labs agent sent over. And
[14:51] I'm also going to simplify the output
[14:53] because we don't want to send the agent
[14:55] back like a ton of information. So we'll
[14:57] execute step and we'll see what sort of
[14:59] results we get back from this node.
[15:01] Okay, so here's the message we got back
[15:03] and we have a little short summary.
[15:04] looks like down here. Although,
[15:06] actually, let's see how short it really
[15:07] is. It pulled from five different
[15:09] sources. And the message is honestly
[15:11] pretty long. So, what we'll probably
[15:13] want to do is feed this message into an
[15:16] AI step that's just going to basically
[15:18] summarize the key highlights. So, that's
[15:20] what I'm going to do real quick. We're
[15:21] going to do that with an AI agent. And
[15:23] this won't take as long because there's
[15:25] no decision-m going on. We're just using
[15:27] the agent to process and summarize
[15:29] information. So, once again, we're not
[15:31] doing the connected chat trigger node.
[15:33] We're going to drag in the output from
[15:34] Perplexity, which is right here. And
[15:37] then for the system message, I'm going
[15:38] to add something really quick. Okay, so
[15:41] for the sake of the demo, I'm saying
[15:42] you're an expert research agent. You
[15:44] will be fed information, and you need to
[15:45] make a concise summary. It should only
[15:47] be about three sentences. Real quick,
[15:49] going to connect another open router
[15:50] chat model to process this information,
[15:52] and we'll test it out and see how
[15:54] concise of a summary it's making. So, we
[15:57] basically get Nvidia reported strong Q4
[15:59] revenue 39 billion blah blah blah. This
[16:03] definitely looks better as a summary
[16:04] that we can send back to our voice agent
[16:06] in 11 Labs. So the final piece of this
[16:08] is we have to use a respond to web hook
[16:10] node to send it back. So I'm going to
[16:12] type in respond. We're going to grab
[16:14] respond to web hook and it's just going
[16:15] to return the first incoming item which
[16:17] is the output from that AI agent
[16:18] already. If you wanted to specify in
[16:21] more detail, you could obviously choose
[16:23] right here. But in order for this to
[16:26] work, we have to make sure that that's
[16:28] set up correctly over here. So right
[16:30] here in the web hook, you can see that
[16:31] it's going to respond immediately. But
[16:33] what we want to do is respond using the
[16:35] respond to web hook node. So now I'm
[16:38] going to go ahead and unpin this data.
[16:39] We're going to save this workflow and
[16:41] I'm basically going to test it out
[16:43] again. So now it's listening for us. And
[16:45] what I can do is open up our 11 labs
[16:48] real quick, test the AI agent, and we
[16:49] will try again. Hello, how can I help
[16:52] you today? Hello, I am looking to do
[16:54] some research.
[16:56] Okay, I can help with that. What topic
[16:58] are you researching? The more specific
[17:00] you are, the better I can assist you.
[17:02] Can you please find out the difference
[17:04] between dogs and cats?
[17:06] Okay, I can definitely help you with
[17:08] that. I will use my search tool to find
[17:10] the key differences between dogs and
[17:12] cats. Give me a moment to gather the
[17:14] information.
[17:16] Okay, I have found some information for
[17:18] you. Dogs and cats differ significantly
[17:20] in several ways. Dogs are generally more
[17:23] social and active during the day,
[17:24] requiring regular exercise, grooming,
[17:26] and outdoor space. Cats, on the other
[17:28] hand, tend to be more independent, are
[17:31] often more active at night, and need
[17:33] less grooming in space, often getting
[17:35] their exercise indoors. Also, dogs
[17:38] communicate openly through body language
[17:41] and vocalizations like barking, while
[17:43] cats use subtler cues and different
[17:45] sounds, such as meowing. Was there
[17:47] anything specific about the differences
[17:48] between cats and dogs that you wanted to
[17:50] know?
[17:51] Nope, that does it. Thank you.
[17:55] Great. I'm glad I could help. Have a
[17:56] great day.
[17:58] Cool. Okay, so that was like not super
[18:00] concise, but it's fine. Um, but the
[18:03] agent, you could see when it realized we
[18:04] were done with our intent, which was
[18:06] looking up dogs and cats, it ended the
[18:08] call on its own. So, just to dive into
[18:10] what happened here, um, the voice agent
[18:13] sent data to the web hook. The web hook
[18:15] is going to wait for the response,
[18:18] does research, the agent summarizes it,
[18:20] sends a summary back to the agent, and
[18:22] you can see as soon as it finished up,
[18:24] that is when Remy started talking again.
[18:27] And obviously, what you'd have to do is
[18:29] prompt this a little bit differently if
[18:30] you want a different type of output. And
[18:32] of course, you'd need to come into your
[18:34] voice agent and go back into the actual
[18:36] system prompting of it if you didn't
[18:38] like the flow of the conversation. For
[18:40] the sake of the demo, I'm just going to
[18:42] leave it here because that was perfectly
[18:43] fine. Um, but you can see it's very
[18:46] similar to the way you would prompt an
[18:47] agent in NADN. Just last thing to keep
[18:49] in mind when you do go to switch this to
[18:51] an active workflow, what you're going to
[18:53] have to do is make sure you switch the
[18:55] web hook in 11 Labs as well because what
[18:57] we gave 11 Labs was a test web hook. So,
[19:00] if I click into the web hook right here,
[19:02] even though it shows test, what you want
[19:04] to do is copy the production URL. And
[19:06] then you just simply go back into your
[19:08] agent. You would scroll down to the tool
[19:10] that we had set up. And you can go ahead
[19:12] and just edit this and paste in your new
[19:14] production URL web hook. And really the
[19:17] only difference is that after web hook
[19:19] right here, you would just get rid of
[19:21] test and then it's the exact same web
[19:22] hook. You go ahead and save it and then
[19:24] test out your AI agent. And just
[19:26] remember when something's active, you
[19:28] won't see it real time, but it will
[19:30] still process in the background. And by
[19:33] the way, once you have an active
[19:34] workflow and an active web hook, you're
[19:36] going to want to check out this video up
[19:37] here where I talk about how you can
[19:38] protect those so that someone isn't
[19:40] abusing your tokens or accessing your
[19:42] data if they shouldn't be. So, that's
[19:43] going to do it for this one. If you guys
[19:45] want to download this workflow just to
[19:46] get started and play around with it, you
[19:48] can do so in my free school community.
[19:50] The link for that will be down in the
[19:51] description. Once you join, you'll just
[19:53] come in here and search for the title of
[19:54] the video or if you click on YouTube
[19:56] resources, you'll be able to find the
[19:57] post associated with the video and then
[19:59] download that workflow right here. And
[20:01] if you're looking for more hands-on
[20:02] experience and you want to take your
[20:04] learning a little bit farther, then
[20:05] definitely check out my paid community.
[20:06] The link for that is also down in the
[20:07] description. We've got a great community
[20:09] of members who are always sharing what
[20:10] they're doing with Naden every single
[20:12] day. And we also have a classroom
[20:13] section with two full courses. Agent
[20:15] Zero is the foundations of AI automation
[20:17] and then 10 hours to 10 seconds where
[20:19] you learn how to identify, design, and
[20:20] build time-saving automations. So, I
[20:23] hope to see you guys in the community.
[20:24] But that's going to do it for this one.
[20:25] If you enjoyed or you learned something
[20:27] new, please give it a like. Definitely
[20:28] helps me out a ton. And as always, I
[20:30] appreciate you guys making it to the end
[20:31] of the video. I'll see you on the next
[20:33] one.