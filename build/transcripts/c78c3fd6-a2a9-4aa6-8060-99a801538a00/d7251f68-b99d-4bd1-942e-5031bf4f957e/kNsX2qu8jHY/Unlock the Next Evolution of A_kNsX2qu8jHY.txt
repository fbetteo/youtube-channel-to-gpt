Video Title: Unlock the Next Evolution of Agents with Human-like Memory (n8n + zep)
Video ID: kNsX2qu8jHY
URL: https://www.youtube.com/watch?v=kNsX2qu8jHY
View Count: 88,733

[00:00] Today I'm going to be talking about the
[00:01] next evolution of AI agents, which is
[00:03] knowledge graphs for long-term memory.
[00:05] When we set up these relational graphs,
[00:06] our agents are able to look through
[00:08] them, understand relations between
[00:09] different entities and different things
[00:11] that you've talked about in the past,
[00:12] and use them to actually be way more
[00:14] intelligent. So, I'm going to show you
[00:15] guys how easy it is to get set up. I'm
[00:17] going to explain what's going on. And
[00:18] another thing I wanted to say is that
[00:19] relational graphs like these can get
[00:21] very expensive very quick if you're not
[00:23] managing it. So, I'm also going to show
[00:24] you guys how I set up this system to
[00:26] make sure that we're not just running up
[00:27] API credits. If all that sounds good to
[00:29] you, let's get started. The first time
[00:30] you set up memory for your AI agent, you
[00:32] probably did so with the simple memory,
[00:34] which just stores it in Nad, which works
[00:36] fine because if I send off this message,
[00:38] the agent will basically check the
[00:39] memory, see if we've talked at all, and
[00:41] then it will also store our interaction
[00:43] in the memory. So now that I just told
[00:45] the agent that my name's Nate, I can go
[00:46] ahead and say, "What is my name?" It's
[00:48] going to check the memory, see my name's
[00:49] Nate, and then respond back to us and
[00:50] say, "Your name is Nate." And this is
[00:52] great because it allows our agent to
[00:54] have a context window to remember what's
[00:56] going on throughout the interaction. But
[00:57] the limitation here is that it's only
[00:59] looking at past interactions. So if I go
[01:01] to the logs and we click on the simple
[01:02] memory, we can see what it does is it
[01:04] looks at our past interaction which was
[01:06] hello, my name is Nate, hello Nate, and
[01:08] then at the end it stores all of that
[01:09] back in. So now it has this to look at
[01:12] next time we talk to it. But the problem
[01:13] with the system is there's no aspect of
[01:15] long-term memory because the agents only
[01:17] being able to look at the past 5, 10, or
[01:20] 15 interactions, something like that.
[01:21] And if we want the agent to remember
[01:23] things about our business or about us
[01:24] personally, our preferences, stuff like
[01:26] that, then we want to set up some form
[01:28] of long-term memory. So the way that
[01:29] we're going to be doing that today is
[01:31] with a user relational graph and we're
[01:33] going to be using Zep in order to do
[01:35] that. Let me show you guys a real quick
[01:36] example. If I just connect the memory to
[01:38] Zep rather than the simple memory and
[01:41] I'll go ahead and send off a query. All
[01:42] right, so I don't know why this is
[01:43] spinning. I think it's just a bug. Our
[01:45] Telegram's listening for us and we're
[01:46] connected to Zep memory. So I'm going to
[01:48] send off what kind of videos should I
[01:50] make this month? The agent's looking in
[01:51] our relationship graph. It's looking to
[01:53] see what we've talked about the past
[01:54] couple interactions. And now it's going
[01:56] to respond to us because it knows things
[01:58] about me and about my YouTube channel.
[02:00] So, you can see we got a pretty lengthy
[02:01] message. Basically just says, "Great
[02:03] question, Nate. Since you're expanding
[02:04] your YouTube channel from pure edit
[02:06] tutorials into more business related AI
[02:08] automation content, which should be
[02:09] coming soon, and you're moving to
[02:10] Chicago soon, here's a tailored list of
[02:12] video ideas you can create this month
[02:14] that blend these themes and appeal to
[02:16] your target audience of business owners,
[02:17] entrepreneurs, and marketers." And what
[02:19] you guys can see is I didn't say any of
[02:20] that context. It was able to just go
[02:22] pull it based on our user graph. And I'm
[02:24] not going to read all this, but
[02:25] basically, you know, automate your move
[02:27] using edit to simplify a relocation, top
[02:29] five a automation use cases for small
[02:31] businesses, all this kind of stuff
[02:32] that's very tailored towards me because
[02:34] it understands me as a person. And just
[02:37] to show you guys what this looks like on
[02:38] the back end, I'm going to head over to
[02:40] Zep real quick. And what I'm in right
[02:41] now is my user relationship graph. So
[02:44] you can see right here is me. I'm the
[02:46] main entity of this user. And I have all
[02:48] of these different relationships and you
[02:50] can see that between each one it
[02:52] basically tells you what that
[02:53] relationship is. So right here we have
[02:55] Nate and we have NAND and the connection
[02:57] is that I use this tool. We can also see
[03:00] that I have YouTube videos on a
[03:02] automation using NAND which uses NAN and
[03:05] Nate creates content on YouTube videos.
[03:07] We have all these other things about
[03:08] NADN can be automated with email
[03:10] marketing can be automated with
[03:11] invoicing. And so the more that we chat
[03:13] with our AI agent, the smarter and
[03:15] smarter it would get because it's adding
[03:16] more relationships and just knows more
[03:18] about me and my business. I can even
[03:20] click on myself, the user, and it will
[03:22] tell me a bit of a summary. I can also
[03:24] click on the different entities, which
[03:25] are the things in pink. Like if I click
[03:26] on Naden, it will say that Nate Herk is
[03:28] a YouTuber focusing on AI automation
[03:30] using NIDN. And I could come down here
[03:32] to business owners and it would say the
[03:34] entity business owners encompasses
[03:36] individuals who own or manage businesses
[03:38] interested in tools like NIDN. So, that
[03:40] was just a quick example and I know it
[03:42] may look a little overwhelming because I
[03:43] have a lot of data in here. So, what
[03:45] we're going to do is I'm going to delete
[03:46] this and we're going to set up a new
[03:48] user and a new graph and everything
[03:50] together so you guys can see how the
[03:52] agent populates it. All right, so I just
[03:54] deleted the user and I'm going to go
[03:55] back into my NAN here and we're going to
[03:57] start chatting with this agent and now
[03:59] it's going to have no memory about us
[04:00] and we're going to start from scratch.
[04:02] All right, so I'm saying hello, ask me
[04:04] questions to get to know me and there's
[04:06] nothing in the memory as you guys can
[04:07] see. It's going to come back and ask us
[04:08] some questions. So, I'm responding to
[04:10] the agent by saying, "My name is Jim. I
[04:12] love playing soccer and I live in
[04:14] Florida in the United States." And as
[04:15] you can see, it's going to ask us more
[04:17] questions. But real quick, let's go over
[04:18] to Zep and let's see if we have a new
[04:20] user created. If I just refresh, we
[04:22] should see we now have this user. And if
[04:24] I click into the user, we have two
[04:25] things to look at. The first one is the
[04:28] sessions. So, these sessions are
[04:29] basically the same way we have that
[04:30] context where it's going to store these
[04:32] pairs of what was the human message and
[04:34] what was the AI response. So, we're
[04:36] still going to get that context window
[04:37] using Zep. But then if I click into the
[04:39] graph, this is where we're going to have
[04:40] that knowledge graph with different
[04:42] relationships start to form. So this is
[04:44] us. This is the user. You can see the
[04:46] summary says the user ID blank is named
[04:48] Jim. He's interested in playing soccer.
[04:50] So we have this over here which is a
[04:51] like. We have this down here which is
[04:53] lives in Florida. And then we have our
[04:55] AI assistant right here. Okay. So I'm
[04:57] going to send off another one that says
[04:58] I play goalie. I don't have a favorite
[05:00] team, but I like watching Messi. So once
[05:02] again, it's searching through a context
[05:04] history. It's searching through
[05:05] information about us. And then it's
[05:06] going to go add more information into
[05:08] our knowledge graph. So let me hit
[05:09] refresh. And we have more relationships.
[05:11] Now us as the user plays the position
[05:13] goalie likes watching Messi. As you can
[05:16] see, it's just going to keep keep
[05:17] growing. And as it learns more, it's
[05:19] going to create these more sophisticated
[05:20] relationships that it can then recall.
[05:22] And just to show you guys what this all
[05:24] looks like, I'm basically just going to
[05:25] send off what should I do this weekend?
[05:27] It's going to get information about us
[05:28] and tell us what we should do. It's
[05:30] probably going to be something related
[05:31] to soccer or maybe something to do with
[05:33] Florida, like going to the beach. So,
[05:35] the agent responded with, "Hey Jim,
[05:36] since you love playing soccer and are a
[05:38] goalie, how about combining your passion
[05:39] with some fun? Join a soccer game or
[05:42] scrimmage. Practice some goalie drills.
[05:43] Explore a new park or beach since you're
[05:45] in Florida, blah blah blah." Exactly
[05:46] like I predicted. But now, what I want
[05:48] to talk about is the issue of this
[05:50] approach. Because as you get more and
[05:53] more different memories and
[05:54] relationships in your Zep knowledge
[05:56] graph, your agent is going to be running
[05:58] through your tokens because it's going
[06:00] to be sending so much context every
[06:02] single time. So when I click into the AI
[06:04] agent and we go to the agent logs, when
[06:06] it hits Zep, we can basically see that
[06:07] it's going to pull back this summary
[06:09] about Jim and then also all of these
[06:11] different facts. So all of the different
[06:13] entities that we have, it's going to
[06:15] comment on. So Messi, Messi is a
[06:17] football player admired by Jim Goalie.
[06:19] Jim is a soccer player who plays goalie
[06:20] in Florida, USA, Florida, all this kind
[06:22] of stuff. And then we also get the
[06:24] context history of here was the first
[06:26] message we sent to each other, here was
[06:28] the second one, here was the third one,
[06:30] all this kind of stuff. So, there's two
[06:32] things going on. We're searching the
[06:33] user graph for information about the
[06:34] user, long-term memories, and then we're
[06:37] searching for context history,
[06:38] conversation history for short-term
[06:40] memory. And all of this context gets
[06:43] passed into our chat model, which is
[06:45] just going to be processing a lot of
[06:46] tokens. So, if I click into open router
[06:49] right here, you can see that this one
[06:50] took 838 total tokens. So, I added even
[06:53] more information to this graph. We have
[06:55] like University of Wisconsin, ice cream,
[06:58] chicken, that kind of stuff. And
[06:59] remember how large my previous one was,
[07:01] the one that we just deleted that was
[07:03] about me. Think about how much more
[07:04] tokens that one was consuming every time
[07:06] we talked to the agent. So now I'm going
[07:08] to show you guys a different method that
[07:09] I came up with to actually be able to
[07:11] pull in the most relevant things from
[07:13] the user graph rather than everything at
[07:15] once. And this is really going to cut
[07:17] down on the amount of tokens that you're
[07:18] sending to your AI model. All right. So
[07:20] what we're doing here is we're accessing
[07:22] Zep's memory, but we're doing it through
[07:24] HTTP request because up here when we do
[07:27] it through the native integration down
[07:28] here, there's really no settings we get
[07:30] to play with. All we get to put in is
[07:31] our key. So we don't have much control.
[07:34] But through the different HTTP requests,
[07:35] we can hit different endpoints and we
[07:37] have a lot more control. So once we send
[07:39] a message to our agent in Telegram, it's
[07:40] going to get the conversation history.
[07:42] It's going to get the actual user graph
[07:44] and it's going to filter it down here
[07:46] and only pull in the three most relevant
[07:48] facts based on the actual message that
[07:50] was sent. Then we're going to merge all
[07:51] that together, give it to the AI agent,
[07:53] and then it's going to respond to us
[07:54] without having to process so many
[07:56] tokens. And then all we have to do is
[07:58] add the memory back so that we can keep
[08:00] making sure the user graph and also the
[08:02] conversation history is accurate. And
[08:04] then we send the message back to us in
[08:05] Telegram. All right, so I'm going to ask
[08:06] it to help me plan my weekend
[08:07] activities. We're going to see it grab
[08:09] conversation history. We're going to see
[08:10] it search the user graph and now it's
[08:13] going to create us a message and then
[08:14] update that memory in the user graph and
[08:16] then we'll take a look at how many
[08:17] tokens it actually ran. So you can see
[08:19] it gave us a very personalized response
[08:20] based on the information that's in our
[08:22] knowledge graph. And now let's take a
[08:23] look at what happened in this actual
[08:25] flow. So the first thing that it does is
[08:27] it goes to get the conversation history
[08:29] using the session ID from our telegram
[08:31] chat. So I'm making a get request to
[08:33] this endpoints and I'm feeding in the
[08:35] session ID. And then down here I'm just
[08:36] saying I only want to pull back 10
[08:38] conversations. So it's basically just
[08:40] five interactions and you can see it
[08:42] comes to us in this really really messy
[08:44] way because it is has all this like
[08:46] metadata. So what I did is I fed that
[08:48] all into a code node and I had it
[08:51] basically just clean it up. So now we're
[08:52] getting one item with all of the
[08:54] conversations. And I've told you guys
[08:55] many times I don't know how to code.
[08:57] What I do is I basically take the
[08:58] incoming JSON when I know I'm going to
[09:00] use a code node to clean it up. I copy
[09:02] it. I go into claude and as you can see
[09:04] here I literally said help me write a
[09:06] code node in nadn that will receive this
[09:08] JSON schema paste in the schema and then
[09:10] I say I need this code node to extract
[09:12] every human message and every AI message
[09:14] as a pair here is an example desired
[09:16] output for the input. So then I gave it
[09:18] a snippet of the input that was actually
[09:19] found right up here and then I said when
[09:21] you get this I want to get this
[09:23] returned. So just clean it up and then
[09:25] it spits out the code. I put it in there
[09:27] and voila. Anyway, so now we have
[09:29] conversation history all cleaned up. And
[09:31] then before we merge it, we have to go
[09:33] get information from the user graph. So
[09:35] once again, I'm making an HTTP request
[09:37] to Zep's API. And then in the body
[09:39] request, I'm able to be a little more
[09:41] specific because we're giving it the
[09:42] user ID to search through. We're giving
[09:44] it the query to search the user graph
[09:46] for, which in this case said, help me
[09:48] plan my weekend activities. We're saying
[09:50] only pull back three facts, and they
[09:52] have to be at least.7 relevant score or
[09:55] higher. So, this in itself already cuts
[09:57] down on the token usage because it's not
[09:59] pulling back every single fact that
[10:01] exists in our user graph. But once
[10:03] again, it comes through really messy and
[10:05] it would just eat up more tokens. So, I
[10:07] did the exact same thing, fed that into
[10:08] a code node, and now we're just getting
[10:10] three interesting facts right here. We
[10:12] merge those two things together. We feed
[10:14] it into the agent. And what I'm doing is
[10:16] I'm giving it the message from Telegram
[10:18] as the user message. But then in the
[10:20] system message, I'm saying you are
[10:21] helpful assistant. Here is some
[10:23] additional information about Nate. And
[10:24] really in this case it should be Jim.
[10:26] And then you see the three facts that
[10:27] were pulled in that were most relevant
[10:29] to the query that triggered the
[10:30] workflow. And then we said here are the
[10:32] five most interactions with Nate where
[10:34] we have the actual interactions down
[10:36] here. So now this agent has full context
[10:38] over some long-term memories about us,
[10:40] our past interactions. And it's not
[10:42] getting fed everything and it's not
[10:43] going to run up our tokens. We're going
[10:45] to add those memories back so that they
[10:46] go into the conversation history and the
[10:48] user graph and then send us a message in
[10:50] Telegram. And real quick, let's take a
[10:51] look at the actual token usage of this
[10:53] run. So this one took 1,045 tokens. So
[10:56] if we just remember that figure real
[10:57] quick. And if we come back up to this
[11:00] workflow and run it again through the
[11:02] other method of using Zep, let's
[11:04] compare. So I sent the exact same
[11:05] message, help me plan my weekend
[11:06] activities. And if we click into the
[11:08] tokens, we can see that it used almost
[11:10] 2.5 times as many, 24,3.
[11:13] And it's because 2,000 of those were the
[11:15] actual prompt tokens. Because if I click
[11:17] into the logs and we go to see what came
[11:20] back from Zep, it had to process this
[11:22] entire thing, which was just so many
[11:24] facts, which didn't really matter for
[11:26] this use case. All these long-term
[11:27] memories just aren't needed for every
[11:29] single time the agent thinks about
[11:31] something. So hopefully you guys can
[11:32] understand why it's actually valuable to
[11:34] be able to split up and only pull back
[11:36] things that are most relevant. And by
[11:38] the way, if you guys want to download
[11:39] this workflow so you can test this out,
[11:41] all you have to do is go to my free
[11:42] school community. The link for that is
[11:43] down in the description. Once you get in
[11:44] here, you'll just come up here and
[11:46] search for the title of the video or
[11:47] click on YouTube resources and find the
[11:49] post associated with this video. And
[11:51] when you click on that post, there will
[11:52] be a JSON file right here for you to
[11:54] download and you can get set up really
[11:56] quick. But there's one thing that you
[11:59] guys may not have noticed about this
[12:00] run. And the only reason I noticed it is
[12:02] cuz I was building it and playing around
[12:03] with it. And the issue here is that when
[12:06] we search through the context window,
[12:08] it's not actually going to grab the five
[12:09] most recent ones. It's grabbing the five
[12:12] first records from our actual zep here.
[12:15] I'm just asking the agent, what's the
[12:17] last thing that we talked about and it's
[12:18] grabbing the context window. And if we
[12:20] click into the actual conversation
[12:21] history, it's pulling back. We can see
[12:23] that the first one it grabbed was that
[12:25] first interaction where I said hello,
[12:26] ask me questions to get to know me
[12:28] better. And you guys remember the last
[12:29] thing we said to our agent was, "Help me
[12:31] plan our weekend." But we don't see that
[12:32] anywhere in here. And I did some
[12:34] research and I figured out that when I
[12:35] was setting up this request, there's no
[12:37] parameter that actually lets us reverse
[12:40] the order of the way we pull back our
[12:42] session messages. So if I go into Zep
[12:44] and we look at our actual session, you
[12:46] can see that if we go to the next page,
[12:49] we do have all of these most recent
[12:51] messages. But when we make that HTTP
[12:53] request, it doesn't grab from here. It
[12:56] basically just starts at the top and
[12:57] then works its way down. So the
[12:59] workaround would be you pull in all of
[13:01] the conversation history and then you
[13:03] sort of reverse order and then split
[13:05] only the ones you want. But that just
[13:07] seems a little bit more complex. So what
[13:09] I decided to do is use a hybrid method
[13:11] where we're going to use Zep for the
[13:13] user graph for long-term memory and then
[13:15] we're going to just use Postgress for
[13:17] that conversation history of that
[13:19] context window. So just as one final
[13:21] demo, I'm going to send off this message
[13:22] that says where should I move to? I want
[13:24] to go somewhere that appeals to my
[13:25] interests. The workflow is searching for
[13:27] the most relevant long-term memory facts
[13:30] about us. It's going to update the
[13:31] Postgress trap memory for short-term
[13:33] memory. And then it's going to add
[13:34] memory back to Zep because we want to
[13:36] still make sure that the user graph is
[13:38] staying fully up to date. And as you can
[13:39] see, the answer that we get is based on
[13:41] your interest in soccer, political
[13:43] science, and your love for chicken
[13:44] recipes, here are some cities you may
[13:45] want to move to. And if we take a look
[13:47] at the context the agent actually gets,
[13:49] it's getting the additional information
[13:51] about us, which is going to be the three
[13:52] facts. It's getting the user message and
[13:54] then it's going to look in Postgress for
[13:56] that short-term memory. Something else I
[13:58] wanted to touch on real quick was how
[14:00] the session IDs work and how you could
[14:02] really evolve these types of agents with
[14:04] this type of memory to be applicable to
[14:06] different real world use cases. So, as
[14:08] you guys saw, what we were doing is we
[14:10] were using the session ID from the
[14:12] Telegram trigger. So, I was storing my
[14:13] Telegram chat ID as the session ID and
[14:16] that's how Zep knew that it was talking
[14:19] to me every time. So, for the sake of
[14:20] the example, I'm going to come in here
[14:21] and change the session ID just to one
[14:23] because it's a different unique thing.
[14:26] And then let me talk to this agent real
[14:28] quick. Okay. So, I just said to the
[14:30] agent, hello, my name is Mike. And as
[14:32] you guys saw, we put the session ID is
[14:33] one. So, this is a completely different
[14:35] user in Zep. And if I go over to Zep,
[14:38] you can see this is the user. And if I
[14:39] view the graph, this was the one that we
[14:41] just did together for Jim. And now, if I
[14:43] refresh my user section, we're going to
[14:45] see another one just popped up that we
[14:46] just created. And if I view this graph,
[14:48] it's completely fresh and it's going to
[14:50] be about Mike. The reason I wanted to
[14:52] show you guys that is so you understood
[14:53] that this agent is going to be able to
[14:55] have unique long-term storage and memory
[14:57] for each individual person based on that
[15:00] session ID. So if the trigger was Gmail,
[15:02] we could store the email address of the
[15:04] person sending the email as the session
[15:06] ID. So then whenever a new email comes
[15:08] in, the agent will be able to look them
[15:09] up in Zep, look at all their memories,
[15:11] and then respond to them accordingly.
[15:13] And I think it's going to get really
[15:14] powerful when you start to mix this sort
[15:15] of relational user graph memory with a
[15:18] bunch of tool calling and with some more
[15:19] autonomy. It could get really cool. You
[15:21] could have an onboarding agent that
[15:23] remembers things about each individual
[15:24] person that's onboarding. You could have
[15:26] an education or a tutoring bot that
[15:27] remembers something about all of its
[15:29] students and the way that they like to
[15:30] learn. There are tons of use cases.
[15:32] Okay, so we broke down Zep memory. We
[15:34] broke down the difference between
[15:35] short-term and long-term memory. We
[15:37] talked about how to optimize this a
[15:39] little bit for cost and also make sure
[15:40] we still have good short-term memory.
[15:42] And if you want to take your learning
[15:43] even farther and discuss some of this
[15:44] stuff a little bit more in depth, then
[15:46] definitely check out my paid community.
[15:47] The link for that will be down in the
[15:49] description. We've got a great community
[15:50] of members who are building with Naden
[15:51] every single day. And we have two full
[15:53] courses in here. Agent Zero, which is
[15:55] the foundations for AI automation, and
[15:56] then 10 hours to 10 seconds where you
[15:58] learn how to identify, design, and build
[16:01] time-saving automations. So, I'd love to
[16:03] see you guys in this community, or you
[16:04] can join the free one if you want to
[16:05] download every single template that I've
[16:07] shown on YouTube, including this one
[16:09] that you're looking at right here. But
[16:10] that's going to do it for this one. If
[16:11] you guys enjoyed or learned something
[16:13] new, please give it a like. Definitely
[16:14] helps me out a ton. And as always, I
[16:16] appreciate you guys making it to the end
[16:17] of the video. I'll see youall on the
[16:18] next one.